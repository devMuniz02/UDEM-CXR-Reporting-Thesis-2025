{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b72626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.train_comparison import *\n",
    "from utils.processing import image_transform\n",
    "from utils.data.chexpert_dataset import CheXpertDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a42455fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPT2 tokenizer.\n"
     ]
    }
   ],
   "source": [
    "tok = build_tokenizer_from_labels(gpt2=True)\n",
    "pad_id = tok.pad_token_id\n",
    "eos_id = tok.eos_token_id\n",
    "bos_id = tok.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19eeaa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering rows with missing PNGs...\n",
      "[INFO] Kept 63/63 rows with existing PNGs\n"
     ]
    }
   ],
   "source": [
    "from utils.data.dataloaders import create_dataloaders\n",
    "\n",
    "# # CheXpert\n",
    "# CHEXPERT_DIR = \"Datasets/CheXpertPlus\"\n",
    "# chexpert_paths = {\n",
    "#     \"chexpert_data_path\": f\"{CHEXPERT_DIR}/PNG\",  # base PNG folder\n",
    "#     \"chexpert_data_csv\": f\"{CHEXPERT_DIR}/df_chexpert_plus_240401_findings.csv\",\n",
    "# }\n",
    "\n",
    "# # MIMIC\n",
    "# MIMIC_DIR = \"Datasets/MIMIC\"\n",
    "# mimic_paths = {\n",
    "#     \"mimic_data_path\": MIMIC_DIR,\n",
    "#     \"mimic_splits_csv\": f\"{MIMIC_DIR}/mimic-cxr-2.0.0-split.csv.gz\",\n",
    "#     \"mimic_metadata_csv\": f\"{MIMIC_DIR}/mimic-cxr-2.0.0-metadata-findings-only.csv\",\n",
    "#     \"mimic_reports_path\": f\"{MIMIC_DIR}/cxr-record-list.csv.gz\",  # must contain 'path'\n",
    "#     \"mimic_images_dir\": f\"{MIMIC_DIR}/matched_images_and_masks_mimic_224/images\",\n",
    "# }\n",
    "\n",
    "# CheXpert\n",
    "CHEXPERT_DIR = \"Datasets/CheXpertPlus\"\n",
    "chexpert_paths = {\n",
    "    \"chexpert_data_path\": \"Datasets/CHEXPERT516\",  # base PNG folder\n",
    "    \"chexpert_data_csv\": f\"{CHEXPERT_DIR}/df_chexpert_plus_240401_findings.csv\",\n",
    "}\n",
    "\n",
    "# MIMIC\n",
    "MIMIC_DIR = \"Datasets/MIMIC\"\n",
    "mimic_paths = {\n",
    "    \"mimic_data_path\": MIMIC_DIR,\n",
    "    \"mimic_splits_csv\": f\"{MIMIC_DIR}/mimic-cxr-2.0.0-split.csv.gz\",\n",
    "    \"mimic_metadata_csv\": f\"{MIMIC_DIR}/mimic-cxr-2.0.0-metadata-findings-only.csv\",\n",
    "    \"mimic_reports_path\": f\"{MIMIC_DIR}/cxr-record-list.csv.gz\",  # must contain 'path'\n",
    "    \"mimic_images_dir\": \"Datasets/MIMIC516/datos\",\n",
    "}\n",
    "\n",
    "import os\n",
    "kwargs = {\n",
    "    # \"num_workers\": os.cpu_count() // 2 if os.cpu_count() else 4,  # adjust on your VM\n",
    "    # \"persistent_workers\": True,           # reuses workers between iterations\n",
    "    # \"prefetch_factor\": 4,                 # each worker prefetches batches\n",
    "    # \"pin_memory\": True,                   # if using CUDA\n",
    "    # \"drop_last\": False\n",
    "}\n",
    "\n",
    "test_loader = create_dataloaders(\n",
    "    chexpert_paths, \n",
    "    mimic_paths, \n",
    "    batch_size=4,\n",
    "    split=\"test\", \n",
    "    sampling_ratio=0.7,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c438d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Cargando encoder DINOv3...\n",
      "Loaded segmenter weights from models/dino_unet_organos_best.pth\n",
      "Loaded segmenter weights from models/dino_unet_decoder_finetuned.pth\n",
      "Set use_cache=False for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/616 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 616/616 [10:24<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "Overall results for model trained 100 epochs:\n",
      "chexbert_f1_weighted: 0.33270280325896656\n",
      "chexbert_f1_micro: 0.33335252461281595\n",
      "chexbert_f1_macro: 0.2295067626545221\n",
      "chexbert_f1_micro_5: 0.40838974586616356\n",
      "chexbert_f1_macro_5: 0.37603624030106914\n",
      "radgraph_f1_RG_E: 0.1700120508539722\n",
      "radgraph_f1_RG_ER: 0.1495862823696185\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.text_metrics import evaluate_all_metrics, save_metrics_to_json\n",
    "# Load weights directly to DEVICE\n",
    "from utils.models.complete_model import create_complete_model, load_complete_model\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEGMENTER_MODEL_PATH_LUNG = f\"models/dino_unet_decoder_finetuned.pth\"\n",
    "SEGMENTER_MODEL_PATH_HEART = f\"models/dino_unet_organos_best.pth\"\n",
    "model = create_complete_model(device=DEVICE, SEGMENTER_MODEL_PATH_LUNG=SEGMENTER_MODEL_PATH_LUNG, SEGMENTER_MODEL_PATH_HEART=SEGMENTER_MODEL_PATH_HEART, freeze_encoder=False, mask_implementation=\"hidden\")\n",
    "best_model_path = \"checkpoints/model_best7.pth\"\n",
    "ckpt = torch.load(best_model_path, map_location=\"cpu\")\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"], strict=False)\n",
    "model.eval()\n",
    "\n",
    "generated_text, target_text = [], []\n",
    "iteration = 0\n",
    "from tqdm import tqdm\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for pixel_values, ids_loader, paths, raw_labels in tqdm(test_loader):\n",
    "        iteration += 1\n",
    "        \n",
    "        pixel_values = pixel_values.to(model.device, non_blocking=True)\n",
    "\n",
    "        # Visual path\n",
    "        patches = model.encoder(pixel_values)                           # [B,Np,Cenc]\n",
    "        projected_patches = model.linear_projection(patches)            # [B,Np,n_embd]\n",
    "\n",
    "        # Segmentation path per layer\n",
    "        segmented_layers = model.segmenter(pixel_values, model.num_layers) # [B,n_layers,H,W] (per current decoder)\n",
    "\n",
    "\n",
    "        # Generate (disable all plotting/diagnostics for speed)\n",
    "        gen_ids = model.decoder.generate(\n",
    "            inputs_embeds=projected_patches,\n",
    "            max_new_tokens=150,\n",
    "            do_sample=False,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            temperature=1.0,\n",
    "            repetition_penalty=1.2,\n",
    "            num_beams=1,\n",
    "            eos_token_id=eos_id,\n",
    "            pad_token_id=pad_id,\n",
    "            use_cache=True,\n",
    "            segmentation_mask=segmented_layers,\n",
    "            prefix_allowed_length=0,\n",
    "            plot_attention_mask=False,\n",
    "            plot_attention_mask_layer=[],\n",
    "            plot_attention_map=False,\n",
    "            plot_attention_map_layer=[],\n",
    "            plot_attention_map_generation=0,\n",
    "        )\n",
    "        # Move only the ids needed for decoding to CPU\n",
    "        texts = model.tokenizer.batch_decode(gen_ids.detach().cpu(), skip_special_tokens=True)\n",
    "\n",
    "        # Accumulate for final metric pass (metrics often run on CPU/strings anyway)\n",
    "        generated_text.extend(texts)\n",
    "        target_text.extend(ids_loader)\n",
    "\n",
    "        # if iteration >= 50:  # your test cap\n",
    "        #     break\n",
    "\n",
    "data_to_save = {\n",
    "    \"generated\": generated_text,\n",
    "    \"target\": target_text,\n",
    "}\n",
    "import json\n",
    "save_json_path = f\"lstm-vs-gpt/results_complete/bestmodelcloud_generated_texts.json\"\n",
    "with open(save_json_path, \"w\") as f:\n",
    "    json.dump(data_to_save, f, indent=4)\n",
    "\n",
    "# Evaluate once per model\n",
    "eval_results = evaluate_all_metrics(\n",
    "    generated=generated_text,\n",
    "    original=target_text,\n",
    "    evaluation_mode=\"CheXagent\"\n",
    ")\n",
    "\n",
    "print(f\"\\nOverall results for model trained {100} epochs:\")\n",
    "for metric, scores in eval_results.items():\n",
    "    print(f\"{metric}: {scores}\")\n",
    "\n",
    "# add training walltime you tracked\n",
    "eval_results[\"training_time_seconds\"] = 0\n",
    "\n",
    "# Save metrics\n",
    "save_metrics_to_json(\n",
    "    eval_results,\n",
    "    f\"lstm-vs-gpt/results_complete/cloudbestmodel10_20_MIMIC.json\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-chest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
