{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10fbf5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPT import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27c0cef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "[INFO] Kept 47494/223462 rows with existing PNGs under C:\\Users\\emman\\Desktop\\PROYECTOS_VS_CODE\\PRUEBAS_DE_PYTHON\\CheXpertPlus\\PNG\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "valid_df = build_valid_df(CSV_PATH, IMG_ROOT)\n",
    "if valid_df.empty:\n",
    "    print(\"[WARN] No valid rows found; check paths and PNG conversion.\")\n",
    "\n",
    "labels_as_str = valid_df[TEXT_COL].astype(str).tolist()\n",
    "tokenizer = build_tokenizer_from_labels(labels_as_str)\n",
    "pad_id = getattr(tokenizer, \"pad_token_id\", 0)\n",
    "bos_id = getattr(tokenizer, \"bos_token_id\", 1)\n",
    "eos_id = getattr(tokenizer, \"eos_token_id\", 2)\n",
    "\n",
    "# DINO expects 224 or 518 square; 224 is fine here\n",
    "IMG_SIZE = 1024\n",
    "tf = dino_image_transform(img_size=IMG_SIZE)\n",
    "ds = CheXpertDataset(img_root=IMG_ROOT, csv=valid_df, transform=tf, text_col=TEXT_COL)\n",
    "collate_fn = CaptionCollate(tokenizer, pad_id)\n",
    "\n",
    "is_windows = os.name == \"nt\"\n",
    "num_workers = 0 if is_windows else 2\n",
    "persistent_workers = False if num_workers == 0 else True\n",
    "\n",
    "# Full loader (used to sample subsets below)\n",
    "full_loader = DataLoader(\n",
    "    ds,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=persistent_workers,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# Simple split\n",
    "n_total = len(ds)\n",
    "n_train = int(n_total * 0.8)\n",
    "n_valid = int(n_total * 0.9)\n",
    "indices = torch.randperm(n_total).tolist()\n",
    "train_idx, valid_idx, test_idx = indices[:n_train], indices[n_train:n_valid], indices[n_valid:]\n",
    "train_ds = torch.utils.data.Subset(ds, train_idx)\n",
    "valid_ds = torch.utils.data.Subset(ds, valid_idx)\n",
    "test_ds = torch.utils.data.Subset(ds, test_idx)\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, collate_fn=collate_fn, num_workers=num_workers)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=8, shuffle=False, collate_fn=collate_fn, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_ds, batch_size=8, shuffle=False, collate_fn=collate_fn, num_workers=num_workers)\n",
    "\n",
    "# DINO ViT-S/16 hidden size is 384 (for this checkpoint); adjust if you change encoder\n",
    "D_IMG = 384\n",
    "N_PREFIX = 1 #(IMG_SIZE // 16) ** 2  # number of visual prefix tokens (including CLS)\n",
    "model = DinoGPTCaptioner(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    d_img=D_IMG,\n",
    "    pad_id=pad_id,\n",
    "    d_model=512,\n",
    "    n_layer=8,\n",
    "    n_head=8,\n",
    "    n_prefix=N_PREFIX,           # number of visual prefix tokens\n",
    "    max_seq_len=256,\n",
    "    dino_model_id=\"facebook/dinov3-vits16-pretrain-lvd1689m\",\n",
    "    freeze_dino=True,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=3e-4, weight_decay=1e-2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e707439b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=5.0197, PPL=158.71 | Val Loss=4.9587, Val PPL=145.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=4.8745, PPL=135.51 | Val Loss=4.7260, Val PPL=115.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=4.5883, PPL=101.31 | Val Loss=4.5383, Val PPL=95.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=4.4641, PPL=91.01 | Val Loss=4.3915, Val PPL=82.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=4.4340, PPL=86.10 | Val Loss=4.2703, Val PPL=72.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=4.1572, PPL=65.70 | Val Loss=4.1886, Val PPL=67.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=4.1705, PPL=66.34 | Val Loss=4.1035, Val PPL=61.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=4.2007, PPL=68.38 | Val Loss=4.0377, Val PPL=57.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=4.0605, PPL=61.98 | Val Loss=3.9586, Val PPL=53.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=3.8004, PPL=46.32 | Val Loss=3.9243, Val PPL=51.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=3.7708, PPL=44.20 | Val Loss=3.8613, Val PPL=48.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=3.8490, PPL=48.37 | Val Loss=3.8220, Val PPL=46.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=3.7910, PPL=45.56 | Val Loss=3.8114, Val PPL=45.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=3.7840, PPL=45.99 | Val Loss=3.7700, Val PPL=44.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=3.7892, PPL=47.20 | Val Loss=3.7491, Val PPL=43.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss=3.6160, PPL=37.93 | Val Loss=3.7195, Val PPL=41.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss=3.7947, PPL=45.75 | Val Loss=3.6750, Val PPL=40.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss=3.5980, PPL=37.03 | Val Loss=3.6588, Val PPL=39.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss=3.6742, PPL=40.32 | Val Loss=3.6431, Val PPL=38.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss=3.6753, PPL=40.26 | Val Loss=3.6118, Val PPL=37.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss=3.5925, PPL=37.36 | Val Loss=3.5933, Val PPL=36.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss=3.5298, PPL=34.28 | Val Loss=3.5603, Val PPL=35.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss=3.5017, PPL=33.89 | Val Loss=3.5606, Val PPL=35.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss=3.6843, PPL=40.77 | Val Loss=3.5518, Val PPL=35.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss=3.5151, PPL=34.32 | Val Loss=3.5297, Val PPL=34.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss=3.5802, PPL=37.59 | Val Loss=3.5075, Val PPL=33.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss=3.4526, PPL=32.96 | Val Loss=3.5029, Val PPL=33.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train Loss=3.5846, PPL=36.80 | Val Loss=3.4850, Val PPL=33.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss=3.5247, PPL=36.00 | Val Loss=3.4579, Val PPL=32.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss=3.3998, PPL=31.24 | Val Loss=3.4509, Val PPL=31.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss=3.4098, PPL=31.40 | Val Loss=3.4514, Val PPL=31.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.10s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Train Loss=3.3555, PPL=29.61 | Val Loss=3.4219, Val PPL=31.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train Loss=3.4156, PPL=31.23 | Val Loss=3.4307, Val PPL=31.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss=3.4374, PPL=32.22 | Val Loss=3.4108, Val PPL=30.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Train Loss=3.4409, PPL=31.73 | Val Loss=3.4195, Val PPL=30.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss=3.3514, PPL=29.13 | Val Loss=3.4161, Val PPL=30.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Train Loss=3.3434, PPL=28.80 | Val Loss=3.3949, Val PPL=30.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Train Loss=3.3717, PPL=29.67 | Val Loss=3.3876, Val PPL=30.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Train Loss=3.3304, PPL=28.65 | Val Loss=3.3752, Val PPL=29.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Train Loss=3.3279, PPL=28.73 | Val Loss=3.3761, Val PPL=29.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Train Loss=3.4836, PPL=33.00 | Val Loss=3.3767, Val PPL=29.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Train Loss=3.4699, PPL=33.12 | Val Loss=3.3651, Val PPL=29.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Train Loss=3.4131, PPL=30.98 | Val Loss=3.3383, Val PPL=28.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Train Loss=3.2679, PPL=27.18 | Val Loss=3.3347, Val PPL=28.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss=3.2436, PPL=26.86 | Val Loss=3.3334, Val PPL=28.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:11<00:00,  1.11s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss=3.3838, PPL=30.45 | Val Loss=3.3194, Val PPL=28.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss=3.1660, PPL=23.95 | Val Loss=3.3112, Val PPL=27.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train Loss=3.2534, PPL=26.09 | Val Loss=3.3020, Val PPL=27.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train Loss=3.2541, PPL=26.22 | Val Loss=3.2966, Val PPL=27.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss=3.2785, PPL=27.09 | Val Loss=3.2904, Val PPL=27.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:01<00:00,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss=3.3161, Test PPL=27.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ---- Train a few slices just to validate wiring ----\n",
    "for epoch in range(50):\n",
    "    slice_train_loader = islice(train_loader, 10)\n",
    "    slice_valid_loader = islice(valid_loader, 10)\n",
    "    train_stats = train_one_epoch(model, slice_train_loader, optimizer, device, pad_id, num_batches=10, grad_clip=1.0)\n",
    "    val_stats = evaluate(model, slice_valid_loader, device, pad_id, num_batches=10)\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss={train_stats['loss']:.4f}, PPL={train_stats['ppl']:.2f} | \"\n",
    "            f\"Val Loss={val_stats['val_loss']:.4f}, Val PPL={val_stats['val_ppl']:.2f}\")\n",
    "\n",
    "def sequence_ce_loss(logits, labels, pad_id):\n",
    "    \"\"\"\n",
    "    logits: (B, T, V) — corresponds to input_ids[:, :] positions\n",
    "    labels: (B, T) — next tokens; pad ignored\n",
    "    \"\"\"\n",
    "    B, T, V = logits.size()\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=pad_id, label_smoothing=0.1)\n",
    "    return loss_fn(logits.reshape(B * T, V), labels.reshape(B * T))\n",
    "\n",
    "@torch.no_grad()\n",
    "def batch_perplexity(logits, labels, pad_id):\n",
    "    loss = sequence_ce_loss(logits, labels, pad_id)\n",
    "    return float(math.exp(min(loss.item(), 20.0)))\n",
    "\n",
    "slice_test_loader = islice(test_loader, 1)\n",
    "test_stats = evaluate(model, slice_test_loader, device, pad_id, num_batches=1)\n",
    "print(f\"Test Loss={test_stats['val_loss']:.4f}, Test PPL={test_stats['val_ppl']:.2f}\")\n",
    "# ---- Quick generation sanity check ----\n",
    "with torch.no_grad():\n",
    "    for pixel_values, ids_loader, paths, raw_labels in test_loader:\n",
    "        pixel_values = pixel_values.to(device)\n",
    "        gen_ids = model.generate(\n",
    "            pixel_values=pixel_values,\n",
    "            bos_id=bos_id, eos_id=eos_id,\n",
    "            max_new_tokens=256, top_p=0.9, temperature=0.9, greedy=True\n",
    "        )\n",
    "        print(\"Predictions (first batch):\")\n",
    "        for i in range(min(gen_ids.size(0), 8)):\n",
    "            print(f\"\\nGEN {i+1}:\", tokenizer.decode(gen_ids[i].tolist()))\n",
    "            print(f\"TGT {i+1}:\", tokenizer.decode(ids_loader[i].tolist()))\n",
    "            # Calculate loss between generated and target sequences\n",
    "        del pixel_values, ids_loader, paths, raw_labels, gen_ids\n",
    "        torch.cuda.empty_cache()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "547df523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=3.5706, PPL=36.86 | Val Loss=3.4515, Val PPL=32.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=3.4131, PPL=31.49 | Val Loss=3.4323, Val PPL=31.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=3.2753, PPL=27.04 | Val Loss=3.4008, Val PPL=30.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=3.3605, PPL=29.83 | Val Loss=3.3971, Val PPL=30.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=3.2628, PPL=26.89 | Val Loss=3.3726, Val PPL=29.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=3.3077, PPL=27.76 | Val Loss=3.3885, Val PPL=30.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=3.4266, PPL=31.42 | Val Loss=3.3410, Val PPL=28.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=3.2446, PPL=26.70 | Val Loss=3.3534, Val PPL=29.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=3.2936, PPL=27.91 | Val Loss=3.3499, Val PPL=28.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=3.3675, PPL=29.80 | Val Loss=3.3377, Val PPL=28.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=3.3471, PPL=29.35 | Val Loss=3.3474, Val PPL=28.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=3.3975, PPL=30.92 | Val Loss=3.3296, Val PPL=28.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=3.2519, PPL=26.10 | Val Loss=3.3344, Val PPL=28.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=3.4334, PPL=32.21 | Val Loss=3.3039, Val PPL=27.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=3.1466, PPL=23.55 | Val Loss=3.2976, Val PPL=27.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss=3.3756, PPL=29.64 | Val Loss=3.3178, Val PPL=27.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss=3.1805, PPL=24.38 | Val Loss=3.3010, Val PPL=27.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss=3.1777, PPL=24.37 | Val Loss=3.2919, Val PPL=27.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss=3.1367, PPL=23.30 | Val Loss=3.2657, Val PPL=26.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss=3.2188, PPL=25.36 | Val Loss=3.2870, Val PPL=27.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:11<00:00,  1.10s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss=3.2573, PPL=26.09 | Val Loss=3.2778, Val PPL=26.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss=3.2962, PPL=27.22 | Val Loss=3.2688, Val PPL=26.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss=3.2664, PPL=26.64 | Val Loss=3.2663, Val PPL=26.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss=3.3100, PPL=28.39 | Val Loss=3.2542, Val PPL=26.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.10s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss=3.2482, PPL=26.31 | Val Loss=3.2739, Val PPL=26.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss=3.2134, PPL=25.37 | Val Loss=3.2391, Val PPL=25.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss=3.2329, PPL=26.12 | Val Loss=3.2357, Val PPL=25.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train Loss=3.2513, PPL=26.56 | Val Loss=3.2246, Val PPL=25.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss=3.1043, PPL=22.77 | Val Loss=3.2086, Val PPL=25.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss=3.1854, PPL=24.34 | Val Loss=3.2016, Val PPL=24.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss=3.2671, PPL=26.65 | Val Loss=3.2168, Val PPL=25.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Train Loss=3.0931, PPL=22.31 | Val Loss=3.2099, Val PPL=25.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train Loss=3.1025, PPL=22.65 | Val Loss=3.2008, Val PPL=24.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss=3.3099, PPL=27.77 | Val Loss=3.2057, Val PPL=25.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Train Loss=3.0735, PPL=22.07 | Val Loss=3.2065, Val PPL=25.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss=3.1928, PPL=24.92 | Val Loss=3.2116, Val PPL=25.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Train Loss=3.1747, PPL=24.25 | Val Loss=3.1980, Val PPL=24.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Train Loss=3.1213, PPL=23.20 | Val Loss=3.1853, Val PPL=24.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Train Loss=3.2135, PPL=25.27 | Val Loss=3.1678, Val PPL=24.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Train Loss=3.2294, PPL=26.36 | Val Loss=3.1730, Val PPL=24.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Train Loss=3.0920, PPL=22.38 | Val Loss=3.1588, Val PPL=23.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Train Loss=3.1373, PPL=23.67 | Val Loss=3.1598, Val PPL=23.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Train Loss=3.0718, PPL=21.88 | Val Loss=3.1756, Val PPL=24.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Train Loss=3.1625, PPL=24.50 | Val Loss=3.1707, Val PPL=24.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss=2.9365, PPL=19.00 | Val Loss=3.1788, Val PPL=24.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss=3.2469, PPL=26.20 | Val Loss=3.1651, Val PPL=24.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss=3.1072, PPL=22.71 | Val Loss=3.1570, Val PPL=23.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train Loss=3.2467, PPL=26.63 | Val Loss=3.1581, Val PPL=23.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train Loss=3.0437, PPL=21.32 | Val Loss=3.1379, Val PPL=23.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss=3.0657, PPL=21.93 | Val Loss=3.1443, Val PPL=23.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss=3.0535, Test PPL=21.19\n",
      "Predictions (first batch):\n",
      "\n",
      "GEN 1: 1. pa and lateral views of the chest demonstrate stable positioning of a right upper extremity picc line. 2. no evidence of acute cardiopulmonary disease. 3. no significant interval change in cardiomegaly. degenerative changes of the thoracic spine. osteopenia.., no acute osteopenia., no acute osteopenia, with, pleural effusion. ). - 2008 hours demonstrates no acute osteopenia, pulmonary edema., unchanged. - 2008. osteopenia, osteopenia, unchanged. osteopenia, pleural effusion. )., unchanged., unchanged. osteopenia, no acute osteopenia, no significant osteopenia, no acute osteopenia, right - 6 - 6 - 6 - 6 - 2008., md at 10 - 2008 at the thoracic spine. - 6 - 2008. - 2008, no acute osteopenia, no significant osteopenia, no significant interval change in the attending radiographic change.,\n",
      "TGT 1: 1. chest 2 views, demonstrate no focal consolidation or pleural effusion. stable overall aeration and volume 2. cardiac silhouette and vascularity grossly similar to prior.\n",
      "\n",
      "GEN 2: 1. single semi - upright chest radiograph demonstrates stable positioning of support equipment. 2. persistent low lung volumes with persistent bibasilar opacities, left greater than right, which may represent atelectasis or consolidation. 3. stable cardiomegaly.ing of the right hemidiaphragm, unchanged. surgical clips, right internal jugular central venous line, and left - sided chest tube, right internal jugular central venous line, and left - sided picc line, and left - sided chest tube, right - sided chest tube, right - sided chest tube, right - sided chest tube, right - sided picc line, right - sided picc line, right - sided picc line, right - sided chest tube, right - sided chest tube, right - sided chest tube, right - sided chest tube, right - sided chest tube, right - sided chest tube, right - sided chest tube, right - sided chest tube, right - sided chest tube, right internal at tip at, right - sided chest tube, right internal jug - sided chest tube, right internal - sided chest tube, right - sided chest tube, right - sided chest tube, right internal jugular line, right internal jugular central line\n",
      "TGT 2: 1. lines and tubes are unchanged. 2. slightly lower lung volumes. persistent interstitial edema with blurry pulmonary markings. persistent bibasilar opacities. persistent bilateral pleural effusions.\n",
      "\n",
      "GEN 3: 1. pa and lateral views of the chest demonstrate stable positioning of a right upper extremity picc line. 2. no evidence of pneumothorax. 3. no significant interval change in cardiomegaly. 4. no evidence of pulmonary edema. no focal consolidation.. - sided pleural effusion. of the right hemidiaphragm. osteopenia.. osteopenia., no acute osteopenia., unchanged.ous abnormality., the thoracic spine., unchanged. osteopenia, unchanged. osteopenia, unchanged. osteopenia., the thoracic spine., unchanged. osteopenia, md, withous abnormality, the thoracic spine., unchanged., the thoracic spine, md at 10 - 2008, md at, md at 10 - 2008 at the thoracic spine, and osteopenia, md at the thoracic spine, the thoracic spine., unchanged., the thoracic spine, unchanged., unchanged.,\n",
      "TGT 3: 1. lower lung volumes with increased right pleural effusion, increased right basilar opacity that may represent developing consolidation and slight increase in left medial basilar opacity as well. rounded lucency in the right lateral mid zone of the lung may represent residual aerated lung, but abscess or empyema with air within the cavity cannot be excluded. if clinically indicated, recommend ct scan of the chest to evaluate further. 2. linear opacity projected parallel to the patient ' s jaw may represent external wire. please correlate with clinical findings.\n",
      "\n",
      "GEN 4: 1. single semi - upright chest radiograph demonstrates stable positioning of support equipment. 2. persistent low lung volumes with persistent bibasilar opacities, left greater than right, which may represent atelectasis or consolidation. 3. stable cardiomegaly.ing of the right hemidiaphragm, unchanged. surgical clips, right internal jugular central venous line, and left - sided chest tube, right internal jugular central venous line, and left - sided picc line, and left - sided chest tube, right - sided chest tube, right - sided chest tube, right - sided chest tube, right - sided picc line, right - sided picc line, right - sided chest tube, right - sided chest tube, right internal jugular line, right - sided picc line, right - sided chest tube, right - sided chest tube, right - sided chest tube, right - sided chest tube, right - sided chest tube, right - sided chest tube, right internal at tip at, right - sided chest tube, right internal jug - sided chest tube, right internal, right - sided chest tube, right - sided chest tube, right internal jugular central line, right - sided chest tube, right - sided\n",
      "TGT 4: 1. portable semi - erect chest radiograph demonstrates no change in the support devices. 2. stable appearance of the chest with redemonstration of low lung volumes, bibasilar opacities, and left pleural effusion. 3. there is marked prominence of the central pulmonary vasculature. though this may be related to low volumes, recommend clinical correlation for venous congestion. no findings to suggest frank pulmonary edema.\n",
      "\n",
      "GEN 5: 1. single semi - upright chest radiograph demonstrates stable position of the right internal jugular central venous catheter, and right internal jugular central venous catheter. 2. persistent low lung volumes with persistent bibasilar opacities, which may represent atelectasis or consolidation. 3. stable cardiomediastinal silhouette is stable. surgical clips in the left upper extremity picc line, and left - sided pleural effusion., unchanged. - sided chest tube, unchanged.generative change., unchanged., unchanged. - demonstration of the right - sided rib deformities are again seen at the right - sided chest tube, unchanged. line, unchanged., unchanged., right internal jugular central venous catheter, unchanged. - sided chest tube, right internal jugular central venous line, right - sided rib fracture of the right - sided rib fracture, and left upper extubation, right internal jugular central line, unchanged., unchanged., right internal jugular central venous line, unchanged. support devices, unchanged. support devices are again noted. support devices remain line\n",
      "TGT 5: 1. removal of mediastinal drain ; bilateral chest tubes remain in place. 2. small right pneumothorax is again, unchanged in size. 3. increased reticular opacity is again noted in the paramediastinal area consistent with previous radiation. 4. bibasilar parenchymal opacities, left greater than right persists associated with small left sided pleural effusion.\n",
      "\n",
      "GEN 6: 1. single semi - upright chest radiograph demonstrates stable positioning of a right internal jugular central venous catheter, and right internal jugular central venous catheter. 2. persistent low lung volumes with persistent bibasilar opacities, which may represent atelectasis or consolidation. 3. stable cardiomediastinal silhouette is stable. surgical clips in the left upper extremity picc line, and left - sided pleural effusion., unchanged. - sided chest tube, unchanged.generative change., right - sided rib deformities are again seen at the right - sided rib fracture., unchanged. at the right - sided rib fracture of a right - sided rib fracture. line, right internal jugular central venous catheter, unchanged., unchanged., right internal jugular central venous line, right internal jugular central venous catheter, right - sided chest wall, right internal jugular central line, unchanged. - sided chest tube, right internal jugular central venous line, unchanged., right internal jugular central line, right internal jugular central venous catheter, right line\n",
      "TGT 6: 1. portable semierect chest radiograph demonstrates no change in the support devices. 2. lung volumes are low. 3. persistent left retrocardiac opacification and small left pleural effusion.\n",
      "\n",
      "GEN 7: 1. single semi - upright chest radiograph demonstrates stable positioning of a right internal jugular central venous catheter, and right internal jugular central venous catheter. 2. persistent low lung volumes with persistent bibasilar opacities, which may represent atelectasis or consolidation. 3. stable cardiomediastinal silhouette is stable. surgical clips in the left upper extremity picc line, and left - sided pleural effusion., unchanged. - sided chest tube, unchanged.generative change., right - sided rib deformities are again seen at the right - sided rib fracture., unchanged. at the right - sided rib fracture of the right - sided rib fracture. line, right internal jugular central venous catheter, unchanged., unchanged., right internal jugular central venous line, right internal jugular central venous catheter, right - sided chest wall, right internal jugular central line, unchanged. - sided rib fracture, right internal jugular central venous line, unchanged., right internal jugular central line, right internal jugular central venous catheter, right line\n",
      "TGT 7: 1. single portable upright view of the chest dated 5 - 22 - 2008 demonstrates postoperative changes including a right thoracotomy and right midlung zone suture material. 2. mild cardiomegaly with unchanged median sternotomy wires. unchanged left picc line. 3. no significant interval change in mild pulmonary edema, bibasilar opacities, and bilateral pleural effusions.\n",
      "\n",
      "GEN 8: 1. single upright ap view of the chest demonstrates stable positioning of a right upper extremity picc line, and right internal jugular central venous line. 2. no significant interval change in cardiopulmonary disease. 3. persistent low lung volumes with persistent bibasilar opacities, likely representing atelectasis., unchanged. cardiomediastinal silhouette is stable., and pulmonary edema. osteopenia, unchanged., unchanged. - demonstration of a left - sided rib deformity picc line, unchanged., unchanged. - 26 - 26 - 2008 at 11 - 2008 at 05 - 2008 at 05 - 26 - 2008 hours demonstrates no significant interval change. - 2008 : 1 - 2008 hours. - 2008 at 059 hours. - 26 - 2008 hours of the right internal jugular central venous line, right - 2008 hours demonstrates no significant interval change. at 05ic spine, unchanged. hours demonstrates no significant interval change. of a left - 2008. hours. osteopenia, with no significant interval change. ex hours demonstrates no significant change. change.., left pleural\n",
      "TGT 8: 1. pa and lateral views of the chest demonstrates stable positioning of left upper extremity picc. 2. left greater than right bibasilar areas of consolidation are again demonstrated with interval increased patchy opacities in the bilateral mid and lower lung zones. 3. stable bilateral pleural effusions.\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=5e-4, weight_decay=1e-2\n",
    ")\n",
    "\n",
    "# ---- Train a few slices just to validate wiring ----\n",
    "for epoch in range(50):\n",
    "    slice_train_loader = islice(train_loader, 10)\n",
    "    slice_valid_loader = islice(valid_loader, 10)\n",
    "    train_stats = train_one_epoch(model, slice_train_loader, optimizer, device, pad_id, num_batches=10, grad_clip=1.0)\n",
    "    val_stats = evaluate(model, slice_valid_loader, device, pad_id, num_batches=10)\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss={train_stats['loss']:.4f}, PPL={train_stats['ppl']:.2f} | \"\n",
    "            f\"Val Loss={val_stats['val_loss']:.4f}, Val PPL={val_stats['val_ppl']:.2f}\")\n",
    "\n",
    "def sequence_ce_loss(logits, labels, pad_id):\n",
    "    \"\"\"\n",
    "    logits: (B, T, V) — corresponds to input_ids[:, :] positions\n",
    "    labels: (B, T) — next tokens; pad ignored\n",
    "    \"\"\"\n",
    "    B, T, V = logits.size()\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=pad_id, label_smoothing=0.1)\n",
    "    return loss_fn(logits.reshape(B * T, V), labels.reshape(B * T))\n",
    "\n",
    "@torch.no_grad()\n",
    "def batch_perplexity(logits, labels, pad_id):\n",
    "    loss = sequence_ce_loss(logits, labels, pad_id)\n",
    "    return float(math.exp(min(loss.item(), 20.0)))\n",
    "\n",
    "slice_test_loader = islice(test_loader, 1)\n",
    "test_stats = evaluate(model, slice_test_loader, device, pad_id, num_batches=1)\n",
    "print(f\"Test Loss={test_stats['val_loss']:.4f}, Test PPL={test_stats['val_ppl']:.2f}\")\n",
    "# ---- Quick generation sanity check ----\n",
    "with torch.no_grad():\n",
    "    for pixel_values, ids_loader, paths, raw_labels in test_loader:\n",
    "        pixel_values = pixel_values.to(device)\n",
    "        gen_ids = model.generate(\n",
    "            pixel_values=pixel_values,\n",
    "            bos_id=bos_id, eos_id=eos_id,\n",
    "            max_new_tokens=256, top_p=0.9, temperature=0.9, greedy=True\n",
    "        )\n",
    "        print(\"Predictions (first batch):\")\n",
    "        for i in range(min(gen_ids.size(0), 8)):\n",
    "            print(f\"\\nGEN {i+1}:\", tokenizer.decode(gen_ids[i].tolist()))\n",
    "            print(f\"TGT {i+1}:\", tokenizer.decode(ids_loader[i].tolist()))\n",
    "            # Calculate loss between generated and target sequences\n",
    "        del pixel_values, ids_loader, paths, raw_labels, gen_ids\n",
    "        torch.cuda.empty_cache()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee5b6f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=3.0362, PPL=20.97 | Val Loss=3.1141, Val PPL=22.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=3.1639, PPL=23.78 | Val Loss=3.0976, Val PPL=22.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=3.0940, PPL=22.47 | Val Loss=3.0810, Val PPL=22.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=3.0455, PPL=21.23 | Val Loss=3.0688, Val PPL=21.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=3.0456, PPL=21.43 | Val Loss=3.0564, Val PPL=21.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=3.0149, PPL=21.36 | Val Loss=3.0522, Val PPL=21.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=3.1733, PPL=24.66 | Val Loss=3.0552, Val PPL=21.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=3.0237, PPL=20.89 | Val Loss=3.0504, Val PPL=21.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=2.9483, PPL=19.66 | Val Loss=3.0444, Val PPL=21.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=3.0184, PPL=20.72 | Val Loss=3.0405, Val PPL=21.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=2.8831, PPL=18.24 | Val Loss=3.0411, Val PPL=21.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=3.0024, PPL=20.79 | Val Loss=3.0372, Val PPL=21.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=2.9548, PPL=19.55 | Val Loss=3.0316, Val PPL=20.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=2.9375, PPL=20.00 | Val Loss=3.0271, Val PPL=20.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=3.0839, PPL=22.65 | Val Loss=3.0205, Val PPL=20.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss=2.9619, PPL=19.55 | Val Loss=3.0143, Val PPL=20.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss=2.9685, PPL=20.26 | Val Loss=3.0129, Val PPL=20.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss=3.1715, PPL=24.35 | Val Loss=3.0082, Val PPL=20.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss=2.9256, PPL=19.04 | Val Loss=3.0058, Val PPL=20.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss=2.9812, PPL=19.91 | Val Loss=3.0028, Val PPL=20.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss=2.9981, PPL=20.32 | Val Loss=2.9954, Val PPL=20.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss=2.9400, PPL=19.25 | Val Loss=2.9907, Val PPL=20.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss=2.8823, PPL=17.93 | Val Loss=2.9865, Val PPL=20.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:11<00:00,  1.10s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss=3.1005, PPL=23.12 | Val Loss=2.9815, Val PPL=19.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss=2.9005, PPL=18.40 | Val Loss=2.9795, Val PPL=19.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss=2.9261, PPL=18.95 | Val Loss=2.9773, Val PPL=19.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss=2.9423, PPL=19.23 | Val Loss=2.9698, Val PPL=19.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train Loss=3.0021, PPL=20.52 | Val Loss=2.9622, Val PPL=19.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss=3.0216, PPL=20.91 | Val Loss=2.9613, Val PPL=19.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:11<00:00,  1.10s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss=2.9367, PPL=19.13 | Val Loss=2.9589, Val PPL=19.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss=2.9094, PPL=18.57 | Val Loss=2.9556, Val PPL=19.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Train Loss=2.9093, PPL=18.75 | Val Loss=2.9538, Val PPL=19.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train Loss=2.9677, PPL=19.66 | Val Loss=2.9519, Val PPL=19.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss=2.9894, PPL=20.20 | Val Loss=2.9499, Val PPL=19.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Train Loss=2.8552, PPL=17.66 | Val Loss=2.9478, Val PPL=19.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss=2.8450, PPL=17.48 | Val Loss=2.9462, Val PPL=19.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Train Loss=2.8518, PPL=17.52 | Val Loss=2.9439, Val PPL=19.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Train Loss=2.9588, PPL=19.97 | Val Loss=2.9425, Val PPL=19.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Train Loss=2.8285, PPL=17.15 | Val Loss=2.9404, Val PPL=19.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Train Loss=2.9636, PPL=19.63 | Val Loss=2.9388, Val PPL=19.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Train Loss=3.0592, PPL=21.75 | Val Loss=2.9372, Val PPL=19.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.09s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Train Loss=2.9369, PPL=19.28 | Val Loss=2.9367, Val PPL=19.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Train Loss=2.9475, PPL=19.52 | Val Loss=2.9358, Val PPL=19.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Train Loss=2.8677, PPL=17.88 | Val Loss=2.9351, Val PPL=19.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss=2.8265, PPL=17.13 | Val Loss=2.9344, Val PPL=19.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss=2.9300, PPL=18.89 | Val Loss=2.9338, Val PPL=19.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss=2.9102, PPL=18.50 | Val Loss=2.9336, Val PPL=19.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train Loss=2.7937, PPL=16.46 | Val Loss=2.9334, Val PPL=19.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train Loss=2.8331, PPL=17.39 | Val Loss=2.9334, Val PPL=19.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss=2.8511, PPL=17.49 | Val Loss=2.9334, Val PPL=19.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss=2.8813, Test PPL=17.84\n",
      "Predictions (first batch):\n",
      "\n",
      "GEN 1: 1. pa and lateral views of the chest demonstrate stable appearance of the right upper extremity picc line. 2. the lungs are clear without focal consolidation. 3. no pleural effusion. 4. no acute osseous abnormality. degenerative changes of the thoracic spine. degenerative changes of the spine. degenerative changes of the spine. degenerative changes. degenerative changes of the spine. degenerative changes of the spine. degenerative changes of the spine. spine. spine... degenerative changes.. degenerative changes of the spine. degenerative changes of the spine.. spine degenerative changes of the spine. degenerative changes of the spine.. degenerative changes of the spine. degenerative changes of the spine.. degenerative changes of the spine... spine... of the spine.. spine. spine. degenerative changes of the spine. degenerative changes of the spine., and spine. degenerative changes\n",
      "TGT 1: 1. chest 2 views, demonstrate no focal consolidation or pleural effusion. stable overall aeration and volume 2. cardiac silhouette and vascularity grossly similar to prior.\n",
      "\n",
      "GEN 2: 1. interval placement of a right ij central venous catheter with the tip in the right atrium. 2. interval placement of a left subclavian central venous catheter with the tip in the superior vena cava. 3. persistent low lung volumes with bibasilar opacities and small bilateral pleural effusions., right internal jugular central venous catheter, with tip in the superior vena cava.., with the tip in the right atrium., right upper quadrant., unchanged position of the right internal jugular central venous catheter, and right internal jugular central venous catheter, unchanged., unchanged position.., unchanged position of the tip in the tip in the right internal jugular central venous catheter, unchanged position of the tip in the cava.., right internal jugular central venous catheter, right internal jugular central vena cava.., unchanged., unchanged., with the right internal jugular central venous catheter, and right upper extremity picc., and right internal jugular central venous cat\n",
      "TGT 2: 1. lines and tubes are unchanged. 2. slightly lower lung volumes. persistent interstitial edema with blurry pulmonary markings. persistent bibasilar opacities. persistent bilateral pleural effusions.\n",
      "\n",
      "GEN 3: 1. pa and lateral views of the chest demonstrate stable appearance of the right upper extremity picc line. 2. the lungs are clear without focal consolidation. 3. no pleural effusion. 4. no acute osseous abnormality. degenerative changes of the thoracic spine. degenerative changes of the spine. degenerative changes of the spine. degenerative changes. degenerative changes of the spine. degenerative changes of the spine. degenerative changes of the spine. spine. spine... degenerative changes.. degenerative changes of the spine. degenerative changes of the spine.. degenerative changes of the spine.. degenerative changes of the spine. degenerative changes of the spine., and spine. degenerative changes of the spine., with degenerative changes of the spine. spine... of the spine. spine. degenerative changes of the spine. degenerative changes of the spine. degenerative changes of the spine. spine. de\n",
      "TGT 3: 1. lower lung volumes with increased right pleural effusion, increased right basilar opacity that may represent developing consolidation and slight increase in left medial basilar opacity as well. rounded lucency in the right lateral mid zone of the lung may represent residual aerated lung, but abscess or empyema with air within the cavity cannot be excluded. if clinically indicated, recommend ct scan of the chest to evaluate further. 2. linear opacity projected parallel to the patient ' s jaw may represent external wire. please correlate with clinical findings.\n",
      "\n",
      "GEN 4: 1. interval placement of a right internal jugular central venous catheter with the tip in the right atrium. 2. interval increase in pulmonary edema. 3. persistent bilateral pleural effusions. 4. stable cardiomegaly., unchanged., unchanged., unchanged., unchanged., unchanged., unchanged., left - sided rib fracture., unchanged.., with a left - sided rib fracture of the right humeral head., unchanged., unchanged.........., unchanged., unchanged right rib fracture..., unchanged.., with a left - to the left lung....., with a left - sided rib fracture., no pneumothorax., with a left humeral head.., with a left rib fracture...., unchanged.., unchanged., with the patient is no pneumothorax., unchanged.tion, with a left chest wall.,\n",
      "TGT 4: 1. portable semi - erect chest radiograph demonstrates no change in the support devices. 2. stable appearance of the chest with redemonstration of low lung volumes, bibasilar opacities, and left pleural effusion. 3. there is marked prominence of the central pulmonary vasculature. though this may be related to low volumes, recommend clinical correlation for venous congestion. no findings to suggest frank pulmonary edema.\n",
      "\n",
      "GEN 5: 1. interval placement of a right internal jugular central venous catheter with the tip in the right atrium. 2. no pneumothorax. 3. persistent low lung volumes. 4. persistent bibasilar opacities, left greater than right., which may represent atelectasis or consolidation. in the right upper quadrant., there is no evidence of pneumothorax., there is no evidence of pneumothorax., there is no significant interval change., with a left - sided rib fracture., with the right upper extremity picc, with the right internal jugular central venous catheter, with the tip in the tip in the tip in the patient ' s right internal jugular central venous catheter, and the tip in the right internal jugular central venous catheter, and right internal jugular central venous catheter, unchanged., with the right internal jugular central vena cava., unchanged., with the chest tubes, with the patient ' s tip in the tip in the tip in the patient ' s, unchanged.., unchanged.,\n",
      "TGT 5: 1. removal of mediastinal drain ; bilateral chest tubes remain in place. 2. small right pneumothorax is again, unchanged in size. 3. increased reticular opacity is again noted in the paramediastinal area consistent with previous radiation. 4. bibasilar parenchymal opacities, left greater than right persists associated with small left sided pleural effusion.\n",
      "\n",
      "GEN 6: 1. interval placement of a right internal jugular central venous catheter with the tip in the right atrium. 2. no pneumothorax. 3. persistent low lung volumes. 4. persistent bibasilar opacities, left greater than right., which may represent atelectasis or consolidation. in the right upper quadrant., there is no evidence of pneumothorax., there is no evidence of pneumothorax., there is no significant interval change., with a left - sided rib fracture., with the right upper extremity picc, with the right internal jugular central venous catheter, with the tip in the tip in the tip in the patient ' s right internal jugular central venous catheter, and the tip in the right internal jugular central venous catheter, and right internal jugular central venous catheter, unchanged., with the right internal jugular central vena cava., unchanged., with the chest tubes, with the patient ' s lines and the tip in the tip in the patient ' s tip in the tip in the patient ' s,\n",
      "TGT 6: 1. portable semierect chest radiograph demonstrates no change in the support devices. 2. lung volumes are low. 3. persistent left retrocardiac opacification and small left pleural effusion.\n",
      "\n",
      "GEN 7: 1. interval placement of a right internal jugular central venous catheter with the tip in the right atrium. 2. interval increase in left lower lobe opacity, which may represent atelectasis or consolidation. 3. stable small left pleural effusion., with tip in the right atrium., unchanged., with tip in the right atrium., unchanged., unchanged appearance of the right upper extremity picc line, and left - sided pleural effusion., unchanged., unchanged position., unchanged., unchanged., unchanged position., unchanged., unchanged position of the right internal jugular central venous catheter, unchanged., with the right ij line, unchanged...., with the tip in the right internal jugular central venous catheter, tip in position of the right internal jugular central venous catheter, unchanged., unchanged. at the right internal jugular central venous catheter, unchanged., unchanged., unchanged appearance of the right internal jugular central venous catheter, unchanged., with,\n",
      "TGT 7: 1. single portable upright view of the chest dated 5 - 22 - 2008 demonstrates postoperative changes including a right thoracotomy and right midlung zone suture material. 2. mild cardiomegaly with unchanged median sternotomy wires. unchanged left picc line. 3. no significant interval change in mild pulmonary edema, bibasilar opacities, and bilateral pleural effusions.\n",
      "\n",
      "GEN 8: 1. interval removal of right internal jugular central venous catheter. 2. no evidence of pneumothorax. 3. persistent left lower lobe opacity., with no evidence of acute cardiopulmonary disease., no evidence of acute disease. degenerative changes of the thoracic spine. spine., no acute osseous abnormality. degenerative changes of the thoracic spine. degenerative changes of the spine. degenerative changes of the spine. degenerative changes of the spine. degenerative changes of the spine., no acute osteopenia. degenerative changes of the spine.. degenerative changes of the spine.., no acute osteopenia and degenerative changes of the spine. spine., no acute osteopenia, with degenerative changes of the thoracic spine.. spine., and degenerative changes of the spine. spine. spine., no acute degenerative changes of the thoracic spine..tion of the spine. degenerative changes\n",
      "TGT 8: 1. pa and lateral views of the chest demonstrates stable positioning of left upper extremity picc. 2. left greater than right bibasilar areas of consolidation are again demonstrated with interval increased patchy opacities in the bilateral mid and lower lung zones. 3. stable bilateral pleural effusions.\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=2e-4, weight_decay=1e-2\n",
    ")\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "# ---- Train a few slices just to validate wiring ----\n",
    "for epoch in range(50):\n",
    "    slice_train_loader = islice(train_loader, 10)\n",
    "    slice_valid_loader = islice(valid_loader, 10)\n",
    "    train_stats = train_one_epoch(model, slice_train_loader, optimizer, device, pad_id, num_batches=10, grad_clip=1.0)\n",
    "    val_stats = evaluate(model, slice_valid_loader, device, pad_id, num_batches=10)\n",
    "    lr_scheduler.step()\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss={train_stats['loss']:.4f}, PPL={train_stats['ppl']:.2f} | \"\n",
    "            f\"Val Loss={val_stats['val_loss']:.4f}, Val PPL={val_stats['val_ppl']:.2f}\")\n",
    "\n",
    "def sequence_ce_loss(logits, labels, pad_id):\n",
    "    \"\"\"\n",
    "    logits: (B, T, V) — corresponds to input_ids[:, :] positions\n",
    "    labels: (B, T) — next tokens; pad ignored\n",
    "    \"\"\"\n",
    "    B, T, V = logits.size()\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=pad_id, label_smoothing=0.1)\n",
    "    return loss_fn(logits.reshape(B * T, V), labels.reshape(B * T))\n",
    "\n",
    "@torch.no_grad()\n",
    "def batch_perplexity(logits, labels, pad_id):\n",
    "    loss = sequence_ce_loss(logits, labels, pad_id)\n",
    "    return float(math.exp(min(loss.item(), 20.0)))\n",
    "\n",
    "slice_test_loader = islice(test_loader, 1)\n",
    "test_stats = evaluate(model, slice_test_loader, device, pad_id, num_batches=1)\n",
    "print(f\"Test Loss={test_stats['val_loss']:.4f}, Test PPL={test_stats['val_ppl']:.2f}\")\n",
    "# ---- Quick generation sanity check ----\n",
    "with torch.no_grad():\n",
    "    for pixel_values, ids_loader, paths, raw_labels in test_loader:\n",
    "        pixel_values = pixel_values.to(device)\n",
    "        gen_ids = model.generate(\n",
    "            pixel_values=pixel_values,\n",
    "            bos_id=bos_id, eos_id=eos_id,\n",
    "            max_new_tokens=256, top_p=0.9, temperature=0.9, greedy=True\n",
    "        )\n",
    "        print(\"Predictions (first batch):\")\n",
    "        for i in range(min(gen_ids.size(0), 8)):\n",
    "            print(f\"\\nGEN {i+1}:\", tokenizer.decode(gen_ids[i].tolist()))\n",
    "            print(f\"TGT {i+1}:\", tokenizer.decode(ids_loader[i].tolist()))\n",
    "            # Calculate loss between generated and target sequences\n",
    "        del pixel_values, ids_loader, paths, raw_labels, gen_ids\n",
    "        torch.cuda.empty_cache()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23867cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPT import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4798884f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "[INFO] Kept 47494/223462 rows with existing PNGs under C:\\Users\\emman\\Desktop\\PROYECTOS_VS_CODE\\PRUEBAS_DE_PYTHON\\CheXpertPlus\\PNG\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "valid_df = build_valid_df(CSV_PATH, IMG_ROOT)\n",
    "if valid_df.empty:\n",
    "    print(\"[WARN] No valid rows found; check paths and PNG conversion.\")\n",
    "\n",
    "labels_as_str = valid_df[TEXT_COL].astype(str).tolist()\n",
    "tokenizer = build_tokenizer_from_labels(labels_as_str)\n",
    "pad_id = getattr(tokenizer, \"pad_token_id\", 0)\n",
    "bos_id = getattr(tokenizer, \"bos_token_id\", 1)\n",
    "eos_id = getattr(tokenizer, \"eos_token_id\", 2)\n",
    "\n",
    "import pandas as pd\n",
    "df_train = pd.read_csv(r\"C:\\Users\\emman\\Desktop\\PROYECTOS_VS_CODE\\PRUEBAS_DE_PYTHON\\PadChest-GR\\master_table.csv\")   # must contain column 'ImageID'\n",
    "root_dir = r'C:\\Users\\emman\\Desktop\\PROYECTOS_VS_CODE\\PRUEBAS_DE_PYTHON\\PadChest-GR\\PadChest_GR'\n",
    "json_file = r\"C:\\Users\\emman\\Desktop\\PROYECTOS_VS_CODE\\PRUEBAS_DE_PYTHON\\PadChest-GR\\grounded_reports_20240819.json\"\n",
    "\n",
    "# Uncomment and set your variables before running:\n",
    "\n",
    "dataframe=df_train\n",
    "root_dir=root_dir\n",
    "json_file=json_file\n",
    "batch_size=8\n",
    "num_workers=0    # try 0 if on Windows/Colab and you hit issues\n",
    "image_size=1024\n",
    "max_txt_len=64   # None => auto from p95+8; or set e.g. 64\n",
    "sentence_key=\"sentence_en\"\n",
    "return_paths=False\n",
    "\n",
    "\n",
    "# DINO expects 224 or 518 square; 224 is fine here\n",
    "IMG_SIZE = 516\n",
    "tf = dino_image_transform(img_size=IMG_SIZE)\n",
    "ds = PadChestGRDataset(\n",
    "        dataframe=dataframe,\n",
    "        root_dir=root_dir,\n",
    "        json_file=json_file,\n",
    "        # tokenizer=tokenizer,\n",
    "        max_txt_len=max_txt_len,\n",
    "        image_size=image_size,\n",
    "        normalize=True,\n",
    "        transform=None,\n",
    "        return_paths=return_paths,\n",
    "        sentence_key=sentence_key,\n",
    "    )\n",
    "collate_fn = CaptionCollate(tokenizer, pad_id)\n",
    "\n",
    "is_windows = os.name == \"nt\"\n",
    "num_workers = 0 if is_windows else 2\n",
    "persistent_workers = False if num_workers == 0 else True\n",
    "\n",
    "# Full loader (used to sample subsets below)\n",
    "full_loader = DataLoader(\n",
    "    ds,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=persistent_workers,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# Simple split\n",
    "n_total = len(ds)\n",
    "n_train = int(n_total * 0.8)\n",
    "n_valid = int(n_total * 0.9)\n",
    "indices = torch.randperm(n_total).tolist()\n",
    "train_idx, valid_idx, test_idx = indices[:n_train], indices[n_train:n_valid], indices[n_valid:]\n",
    "train_ds = torch.utils.data.Subset(ds, train_idx)\n",
    "valid_ds = torch.utils.data.Subset(ds, valid_idx)\n",
    "test_ds = torch.utils.data.Subset(ds, test_idx)\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, collate_fn=collate_fn, num_workers=num_workers)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=8, shuffle=False, collate_fn=collate_fn, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_ds, batch_size=8, shuffle=False, collate_fn=collate_fn, num_workers=num_workers)\n",
    "\n",
    "# DINO ViT-S/16 hidden size is 384 (for this checkpoint); adjust if you change encoder\n",
    "D_IMG = 384\n",
    "N_PREFIX = (IMG_SIZE // 16) ** 2  # number of visual prefix tokens (including CLS)\n",
    "model = DinoGPTCaptioner(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    d_img=D_IMG,\n",
    "    pad_id=pad_id,\n",
    "    d_model=512,\n",
    "    n_layer=8,\n",
    "    n_head=8,\n",
    "    n_prefix=N_PREFIX,           # number of visual prefix tokens\n",
    "    max_seq_len=256,\n",
    "    dino_model_id=\"facebook/dinov3-vits16-pretrain-lvd1689m\",\n",
    "    freeze_dino=True,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=3e-4, weight_decay=1e-2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d84dd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:15<00:00,  1.50s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:12<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=5.3876, PPL=229.32 | Val Loss=5.0213, Val PPL=156.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:13<00:00,  1.39s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:12<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=5.0247, PPL=158.94 | Val Loss=4.8419, Val PPL=131.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:14<00:00,  1.44s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:12<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=4.6620, PPL=111.94 | Val Loss=4.6466, Val PPL=107.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:14<00:00,  1.45s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:12<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=4.6839, PPL=111.22 | Val Loss=4.4717, Val PPL=89.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:13<00:00,  1.38s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:12<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=4.5141, PPL=93.33 | Val Loss=4.3342, Val PPL=77.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:14<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:12<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=4.5650, PPL=98.48 | Val Loss=4.2024, Val PPL=68.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:14<00:00,  1.40s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:12<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=4.5157, PPL=96.30 | Val Loss=4.1071, Val PPL=62.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:14<00:00,  1.46s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:12<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=4.1965, PPL=69.13 | Val Loss=3.9982, Val PPL=55.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:13<00:00,  1.40s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:12<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=4.1955, PPL=72.59 | Val Loss=3.9257, Val PPL=51.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:14<00:00,  1.45s/it]\n",
      "Evaluating: 100%|██████████| 10/10 [00:12<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=4.0994, PPL=65.82 | Val Loss=3.8567, Val PPL=48.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss=4.0042, Test PPL=54.83\n",
      "Predictions (first batch):\n",
      "\n",
      "GEN 1: no significant findings.\n",
      "TGT 1: within normal limits.\n",
      "\n",
      "GEN 2: no significant findings.\n",
      "TGT 2: within normal limits.\n",
      "\n",
      "GEN 3: no significant findings.\n",
      "TGT 3: biapical pleuroparenchymal thickening. bone island in the right humeral head.\n",
      "\n",
      "GEN 4: no significant findings.\n",
      "TGT 4: cardiomegaly. no infiltrates or lung condensations are appreciated. no pleural effusion is appreciated. dorsal kyphosis. osteopenia. no clear fracture lines are appreciated.\n",
      "\n",
      "GEN 5: no significant findings.\n",
      "TGT 5: chronic pulmonary changes. a small right apical pneumothorax persists. chest drain tube projected over the eighth rib. subcutaneous emphysema.\n",
      "\n",
      "GEN 6: no significant findings.\n",
      "TGT 6: dorsolumbar scoliosis. lobulation of the right hemidiaphragm. hiatal hernia. aortic elongation.\n",
      "\n",
      "GEN 7: no significant findings.\n",
      "TGT 7: cardiomegaly. pacemaker. bilateral gynecomastia. signs of air trapping.\n",
      "\n",
      "GEN 8: no significant findings.\n",
      "TGT 8: no findings of pathological significance.\n"
     ]
    }
   ],
   "source": [
    "# ---- Train a few slices just to validate wiring ----\n",
    "for epoch in range(10):\n",
    "    slice_train_loader = islice(train_loader, 10)\n",
    "    slice_valid_loader = islice(valid_loader, 10)\n",
    "    train_stats = train_one_epoch(model, slice_train_loader, optimizer, device, pad_id, num_batches=10, grad_clip=1.0)\n",
    "    val_stats = evaluate(model, slice_valid_loader, device, pad_id, num_batches=10)\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss={train_stats['loss']:.4f}, PPL={train_stats['ppl']:.2f} | \"\n",
    "            f\"Val Loss={val_stats['val_loss']:.4f}, Val PPL={val_stats['val_ppl']:.2f}\")\n",
    "\n",
    "def sequence_ce_loss(logits, labels, pad_id):\n",
    "    \"\"\"\n",
    "    logits: (B, T, V) — corresponds to input_ids[:, :] positions\n",
    "    labels: (B, T) — next tokens; pad ignored\n",
    "    \"\"\"\n",
    "    B, T, V = logits.size()\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=pad_id, label_smoothing=0.1)\n",
    "    return loss_fn(logits.reshape(B * T, V), labels.reshape(B * T))\n",
    "\n",
    "@torch.no_grad()\n",
    "def batch_perplexity(logits, labels, pad_id):\n",
    "    loss = sequence_ce_loss(logits, labels, pad_id)\n",
    "    return float(math.exp(min(loss.item(), 20.0)))\n",
    "\n",
    "slice_test_loader = islice(test_loader, 1)\n",
    "test_stats = evaluate(model, slice_test_loader, device, pad_id, num_batches=1)\n",
    "print(f\"Test Loss={test_stats['val_loss']:.4f}, Test PPL={test_stats['val_ppl']:.2f}\")\n",
    "# ---- Quick generation sanity check ----\n",
    "with torch.no_grad():\n",
    "    for pixel_values, ids_loader, paths, raw_labels in test_loader:\n",
    "        pixel_values = pixel_values.to(device)\n",
    "        gen_ids = model.generate(\n",
    "            pixel_values=pixel_values,\n",
    "            bos_id=bos_id, eos_id=eos_id,\n",
    "            max_new_tokens=256, top_p=0.9, temperature=0.9, greedy=True\n",
    "        )\n",
    "        print(\"Predictions (first batch):\")\n",
    "        for i in range(min(gen_ids.size(0), 8)):\n",
    "            print(f\"\\nGEN {i+1}:\", tokenizer.decode(gen_ids[i].tolist()))\n",
    "            print(f\"TGT {i+1}:\", tokenizer.decode(ids_loader[i].tolist()))\n",
    "            # Calculate loss between generated and target sequences\n",
    "        del pixel_values, ids_loader, paths, raw_labels, gen_ids\n",
    "        torch.cuda.empty_cache()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71a4099a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:02<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss=3.0177, Test PPL=20.46\n",
      "Predictions (first batch):\n",
      "\n",
      "GEN 1: no significant radiological findings.\n",
      "TGT 1: left basal subsegmental atelectasis. mild changes of dorsal spondylosis.\n",
      "\n",
      "GEN 2: no significant radiological findings.\n",
      "TGT 2: no consolidations are observed. calcified aortic atheromatosis. degenerative mechanical changes in the axial column. calcifications in the region of the bilateral rotator cuffs. no other relevant findings.\n",
      "\n",
      "GEN 3: no significant radiological findings.\n",
      "TGT 3: no alterations.\n",
      "\n",
      "GEN 4: no significant radiological findings.\n",
      "TGT 4: pacemaker through the left subclavian. no signs of pneumothorax. cardiomegaly. mitral ring calcification.\n",
      "\n",
      "GEN 5: no significant radiological findings.\n",
      "TGT 5: prominent aortic button that impresses on the trachea. slight enlargement of the mediastinum secondary to a prominent ascending aorta. known right basal pulmonary nodule, projected over the eighth right posterior rib. free costophrenic sinuses. bilateral gynecomastia.\n",
      "\n",
      "GEN 6: no significant radiological findings.\n",
      "TGT 6: chronic changes in lung parenchyma. signs of air trapping. degenerative mechanical changes in the axial column. aortic elongation. calcified aortic atheromatosis.\n",
      "\n",
      "GEN 7: no significant radiological findings.\n",
      "TGT 7: signs of air trapping.\n",
      "\n",
      "GEN 8: no significant radiological findings.\n",
      "TGT 8: cardiomediastinal silhouette of normal size. no lung consolidations are observed. laminar atelectasis. small pleural effusion.\n"
     ]
    }
   ],
   "source": [
    "slice_test_loader = islice(test_loader, 2)\n",
    "test_stats = evaluate(model, slice_test_loader, device, pad_id, num_batches=1)\n",
    "print(f\"Test Loss={test_stats['val_loss']:.4f}, Test PPL={test_stats['val_ppl']:.2f}\")\n",
    "# ---- Quick generation sanity check ----\n",
    "with torch.no_grad():\n",
    "    for pixel_values, ids_loader, paths, raw_labels in test_loader:\n",
    "        pixel_values = pixel_values.to(device)\n",
    "        gen_ids = model.generate(\n",
    "            pixel_values=pixel_values,\n",
    "            bos_id=bos_id, eos_id=eos_id,\n",
    "            max_new_tokens=64, top_p=0.9, temperature=0.9, greedy=True\n",
    "        )\n",
    "        print(\"Predictions (first batch):\")\n",
    "        for i in range(min(gen_ids.size(0), 16)):\n",
    "            print(f\"\\nGEN {i+1}:\", tokenizer.decode(gen_ids[i].tolist()))\n",
    "            print(f\"TGT {i+1}:\", tokenizer.decode(ids_loader[i].tolist()))\n",
    "            # Calculate loss between generated and target sequences\n",
    "        del pixel_values, ids_loader, paths, raw_labels, gen_ids\n",
    "        torch.cuda.empty_cache()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c01ec3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto stats (may be empty if max_txt_len was provided): {}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'input_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 336\u001b[0m\n\u001b[0;32m    324\u001b[0m ds, loader, stats, tok \u001b[38;5;241m=\u001b[39m build_padchest_loader(\n\u001b[0;32m    325\u001b[0m     dataframe\u001b[38;5;241m=\u001b[39mdf_train,\n\u001b[0;32m    326\u001b[0m     root_dir\u001b[38;5;241m=\u001b[39mroot_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    333\u001b[0m     return_paths\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    334\u001b[0m )\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuto stats (may be empty if max_txt_len was provided):\u001b[39m\u001b[38;5;124m\"\u001b[39m, stats)\n\u001b[1;32m--> 336\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattn_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\emman\\Desktop\\PROYECTOS_VS_CODE\\PRUEBAS_DE_PYTHON\\DINOv3PEF\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 732\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    738\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\emman\\Desktop\\PROYECTOS_VS_CODE\\PRUEBAS_DE_PYTHON\\DINOv3PEF\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    787\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 788\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    790\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\emman\\Desktop\\PROYECTOS_VS_CODE\\PRUEBAS_DE_PYTHON\\DINOv3PEF\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 200\u001b[0m, in \u001b[0;36mcollate_dynamic\u001b[1;34m(batch, pad_to_mult)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(batch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_full\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;66;03m# BioBERT pad token id is typically 0\u001b[39;00m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m dtype_ids  \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    201\u001b[0m dtype_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattn_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    202\u001b[0m device     \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdevice\n",
      "\u001b[1;31mKeyError\u001b[0m: 'input_ids'"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# PadChest-GR Report Loader (BioBERT, no logging, optimized)\n",
    "# =========================\n",
    "import os, json, math, random\n",
    "from typing import Optional, List, Dict, Any, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# -------------------------\n",
    "# 0) Utilities: load texts & analyze lengths with BioBERT tokenizer\n",
    "# -------------------------\n",
    "BIOBERT_ID = \"dmis-lab/biobert-base-cased-v1.1\"\n",
    "\n",
    "def load_texts_by_image(\n",
    "    json_path: str,\n",
    "    sentence_key: str = \"sentence_en\",\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      img_ids: list[str] ImageIDs\n",
    "      texts:   list[str] joined text per ImageID\n",
    "    \"\"\"\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    by_id: Dict[str, List[str]] = {}\n",
    "    for entry in data:\n",
    "        img_id = entry.get(\"ImageID\", \"\")\n",
    "        parts = []\n",
    "        for f in entry.get(\"findings\", []) or []:\n",
    "            s = (f.get(sentence_key) or \"\").strip()\n",
    "            if s:\n",
    "                parts.append(s)\n",
    "        txt = \" \".join(parts).strip()\n",
    "        if img_id:\n",
    "            by_id.setdefault(img_id, [])\n",
    "            if txt:\n",
    "                by_id[img_id].append(txt)\n",
    "\n",
    "    img_ids, texts = [], []\n",
    "    for img_id, chunks in by_id.items():\n",
    "        joined = \" \".join(chunks).strip()\n",
    "        img_ids.append(img_id)\n",
    "        texts.append(joined)\n",
    "    return img_ids, texts\n",
    "\n",
    "def analyze_lengths_with_biobert(\n",
    "    texts: List[str],\n",
    "    tokenizer: Optional[AutoTokenizer] = None,\n",
    "    recommended_quantile: float = 0.95,\n",
    "    margin_tokens: int = 8,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Computes character/word lengths and BioBERT token lengths (fast).\n",
    "    Returns stats + recommended max length (p95 + margin, capped at max).\n",
    "    \"\"\"\n",
    "    if tokenizer is None:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(BIOBERT_ID, use_fast=True)\n",
    "\n",
    "    char_lens = np.fromiter((len(t) for t in texts), dtype=np.int32, count=len(texts))\n",
    "    word_lens = np.fromiter((len(t.split()) for t in texts), dtype=np.int32, count=len(texts))\n",
    "\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        add_special_tokens=True,\n",
    "        padding=False,\n",
    "        truncation=False,\n",
    "        return_length=True,\n",
    "        return_attention_mask=False,\n",
    "        return_token_type_ids=False,\n",
    "    )\n",
    "    token_lens = np.array(enc[\"length\"], dtype=np.int32)\n",
    "\n",
    "    stats = {\n",
    "        \"num_images\": len(texts),\n",
    "        \"chars\": {\"max\": int(char_lens.max() if len(texts) else 0)},\n",
    "        \"words\": {\"max\": int(word_lens.max() if len(texts) else 0)},\n",
    "        \"tokens_biobert\": {\n",
    "            \"max\": int(token_lens.max() if len(texts) else 0),\n",
    "            \"p50\": int(np.percentile(token_lens, 50, method=\"nearest\")) if len(texts) else 0,\n",
    "            \"p75\": int(np.percentile(token_lens, 75, method=\"nearest\")) if len(texts) else 0,\n",
    "            \"p90\": int(np.percentile(token_lens, 90, method=\"nearest\")) if len(texts) else 0,\n",
    "            \"p95\": int(np.percentile(token_lens, 95, method=\"nearest\")) if len(texts) else 0,\n",
    "            \"p99\": int(np.percentile(token_lens, 99, method=\"nearest\")) if len(texts) else 0,\n",
    "        },\n",
    "    }\n",
    "    p95 = stats[\"tokens_biobert\"][\"p95\"]\n",
    "    tmax = stats[\"tokens_biobert\"][\"max\"]\n",
    "    rec = min(tmax, int(p95 + margin_tokens))\n",
    "    stats[\"tokens_biobert\"][\"recommended_max_len\"] = int(rec)\n",
    "    return stats\n",
    "\n",
    "# -------------------------\n",
    "# 1) Dataset (pre-tokenized, fast I/O)\n",
    "# -------------------------\n",
    "class PadChestGRDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Minimal, fast dataset for PadChest-GR report generation.\n",
    "    - Precomputes image paths.\n",
    "    - Pre-tokenizes reports once with BioBERT (or any HF tokenizer).\n",
    "    - No logging, no prints.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe,                 # pandas DataFrame with column 'ImageID'\n",
    "        root_dir: str,\n",
    "        json_file: str,            # grounded_reports_*.json\n",
    "        tokenizer: AutoTokenizer,\n",
    "        max_txt_len: int = 64,\n",
    "        image_size: int = 1024,\n",
    "        normalize: bool = True,\n",
    "        transform=None,\n",
    "        return_paths: bool = False,\n",
    "        sentence_key: str = \"sentence_en\",\n",
    "    ):\n",
    "        self.root_dir = root_dir\n",
    "        self.img_ids: List[str] = dataframe[\"ImageID\"].tolist()\n",
    "        self.img_paths: List[str] = [os.path.join(root_dir, x) for x in self.img_ids]\n",
    "        self.return_paths = return_paths\n",
    "\n",
    "        # Build per-ImageID text in the same order as dataframe\n",
    "        # (join all sentence_en found in JSON for that ImageID)\n",
    "        with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        by_id: Dict[str, List[Dict[str, Any]]] = {\n",
    "            d[\"ImageID\"]: d.get(\"findings\", []) for d in data\n",
    "        }\n",
    "        texts: List[str] = []\n",
    "        for img_id in self.img_ids:\n",
    "            findings = by_id.get(img_id, [])\n",
    "            joined = \" \".join(\n",
    "                (f.get(sentence_key) or \"\").strip()\n",
    "                for f in findings if f.get(sentence_key)\n",
    "            ).strip()\n",
    "            texts.append(joined)\n",
    "\n",
    "        # Image transforms (DINO-friendly normalization by default)\n",
    "        tfs = [transforms.Resize((image_size, image_size)), transforms.ToTensor()]\n",
    "        if normalize:\n",
    "            tfs.append(transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                            std=[0.229, 0.224, 0.225]))\n",
    "        self.transform = transform or transforms.Compose(tfs)\n",
    "\n",
    "        # Pre-tokenize once (truncate to cap, pad to cap for storage)\n",
    "        self.tokenizer = tokenizer\n",
    "        enc = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_txt_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        self.input_ids = enc[\"input_ids\"]          # [N, L]\n",
    "        self.attn_mask = enc[\"attention_mask\"]     # [N, L]\n",
    "        self.seq_len = self.attn_mask.sum(dim=1).to(torch.int32)  # true len <= max_txt_len\n",
    "        self.texts = texts  # keep raw if you need it for eval/debug\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        with Image.open(self.img_paths[idx]).convert(\"RGB\") as im:\n",
    "            image = self.transform(im)\n",
    "        item = {\n",
    "            \"image\": image,\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attn_mask\": self.attn_mask[idx],\n",
    "            \"seq_len\": int(self.seq_len[idx]),\n",
    "        }\n",
    "        if self.return_paths:\n",
    "            item[\"path\"] = self.img_paths[idx]\n",
    "        # return item\n",
    "        return {\"image\": image, \"label\": self.texts[idx], \"seq_len\": int(self.seq_len[idx])}\n",
    "\n",
    "# -------------------------\n",
    "# 2) Dynamic-padding collate (pads to batch max, rounded to mult of 8)\n",
    "# -------------------------\n",
    "def _pad_to_multiple(x: int, m: int) -> int:\n",
    "    r = x % m\n",
    "    return x if r == 0 else x + (m - r)\n",
    "\n",
    "def collate_dynamic(batch: List[Dict[str, Any]], pad_to_mult: int = 8) -> Dict[str, torch.Tensor]:\n",
    "    B = len(batch)\n",
    "    images = torch.stack([b[\"image\"] for b in batch], dim=0)\n",
    "\n",
    "    max_len = max(int(b[\"seq_len\"]) for b in batch)\n",
    "    max_len = _pad_to_multiple(max_len, pad_to_mult)\n",
    "\n",
    "    # Use tokenizer pad_id if available, else 0\n",
    "    pad_id = 0\n",
    "    if \"input_ids\" in batch[0] and hasattr(batch[0][\"input_ids\"], \"new_full\"):\n",
    "        # BioBERT pad token id is typically 0\n",
    "        pass\n",
    "\n",
    "    dtype_ids  = batch[0][\"input_ids\"].dtype\n",
    "    dtype_mask = batch[0][\"attn_mask\"].dtype\n",
    "    device     = batch[0][\"input_ids\"].device\n",
    "\n",
    "    input_ids = torch.full((B, max_len), pad_id, dtype=dtype_ids, device=device)\n",
    "    attn_mask = torch.zeros((B, max_len), dtype=dtype_mask, device=device)\n",
    "\n",
    "    for i, b in enumerate(batch):\n",
    "        L = int(b[\"seq_len\"])\n",
    "        input_ids[i, :L] = b[\"input_ids\"][:L]\n",
    "        attn_mask[i, :L] = b[\"attn_mask\"][:L]\n",
    "\n",
    "    out = {\"images\": images, \"input_ids\": input_ids, \"attn_mask\": attn_mask}\n",
    "    if \"path\" in batch[0]:\n",
    "        out[\"paths\"] = [b[\"path\"] for b in batch]\n",
    "    return out\n",
    "\n",
    "# -------------------------\n",
    "# 3) Length-bucketed batch sampler\n",
    "# -------------------------\n",
    "class LengthBucketBatchSampler(Sampler[List[int]]):\n",
    "    \"\"\"\n",
    "    Groups indices with similar sequence lengths to reduce padding.\n",
    "    \"\"\"\n",
    "    def __init__(self, lengths: List[int], batch_size: int, bucket_size: int = 50, shuffle: bool = True):\n",
    "        self.lengths = lengths\n",
    "        self.batch_size = batch_size\n",
    "        self.bucket_size = max(bucket_size, batch_size)\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.indices = list(range(len(lengths)))\n",
    "        self.indices.sort(key=lambda i: lengths[i])\n",
    "\n",
    "        self.buckets = [\n",
    "            self.indices[i:i+self.bucket_size] for i in range(0, len(self.indices), self.bucket_size)\n",
    "        ]\n",
    "\n",
    "    def __iter__(self):\n",
    "        buckets = self.buckets[:]\n",
    "        if self.shuffle:\n",
    "            random.shuffle(buckets)\n",
    "        for bucket in buckets:\n",
    "            if self.shuffle:\n",
    "                random.shuffle(bucket)\n",
    "            for i in range(0, len(bucket), self.batch_size):\n",
    "                batch = bucket[i:i+self.batch_size]\n",
    "                if batch:\n",
    "                    yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.lengths) / self.batch_size)\n",
    "\n",
    "# -------------------------\n",
    "# 4) Build tokenizer, pick MAX_TXT_LEN, dataset, dataloader\n",
    "# -------------------------\n",
    "def build_padchest_loader(\n",
    "    dataframe,\n",
    "    root_dir: str,\n",
    "    json_file: str,\n",
    "    batch_size: int = 8,\n",
    "    num_workers: int = 4,\n",
    "    image_size: int = 1024,\n",
    "    max_txt_len: Optional[int] = None,   # if None, auto from p95+8\n",
    "    sentence_key: str = \"sentence_en\",\n",
    "    return_paths: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns: dataset, dataloader, stats(dict), tokenizer\n",
    "    \"\"\"\n",
    "    tok = AutoTokenizer.from_pretrained(BIOBERT_ID, use_fast=True)\n",
    "\n",
    "    # Auto-pick max_txt_len if not provided (p95 + 8, capped at max)\n",
    "    if max_txt_len is None:\n",
    "        _, all_texts = load_texts_by_image(json_file, sentence_key=sentence_key)\n",
    "        stats = analyze_lengths_with_biobert(all_texts, tokenizer=tok)\n",
    "        max_txt_len = int(stats[\"tokens_biobert\"][\"recommended_max_len\"])\n",
    "    else:\n",
    "        stats = {}\n",
    "\n",
    "    ds = PadChestGRDataset(\n",
    "        dataframe=dataframe,\n",
    "        root_dir=root_dir,\n",
    "        json_file=json_file,\n",
    "        tokenizer=tok,\n",
    "        max_txt_len=max_txt_len,\n",
    "        image_size=image_size,\n",
    "        normalize=True,\n",
    "        transform=None,\n",
    "        return_paths=return_paths,\n",
    "        sentence_key=sentence_key,\n",
    "    )\n",
    "\n",
    "    # Length-bucketed sampler (use true lengths after truncation)\n",
    "    lengths = ds.seq_len.tolist()\n",
    "    sampler = LengthBucketBatchSampler(\n",
    "        lengths=lengths,\n",
    "        batch_size=batch_size,\n",
    "        bucket_size=8 * batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # num_workers tip: set to 0 on Windows/interactive if you hit issues\n",
    "    loader = DataLoader(\n",
    "        ds,\n",
    "        batch_sampler=sampler,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_dynamic,\n",
    "        persistent_workers=(num_workers > 0),\n",
    "        prefetch_factor=(4 if num_workers > 0 else None),\n",
    "    )\n",
    "    return ds, loader, stats, tok\n",
    "\n",
    "# -------------------------\n",
    "# 5) Example usage (adjust to your paths/DataFrame)\n",
    "# -------------------------\n",
    "\n",
    "# EXAMPLE placeholders (replace with your actual DataFrame and paths)\n",
    "import pandas as pd\n",
    "df_train = pd.read_csv(r\"C:\\Users\\emman\\Desktop\\PROYECTOS_VS_CODE\\PRUEBAS_DE_PYTHON\\PadChest-GR\\master_table.csv\")   # must contain column 'ImageID'\n",
    "root_dir = r'C:\\Users\\emman\\Desktop\\PROYECTOS_VS_CODE\\PRUEBAS_DE_PYTHON\\PadChest-GR\\PadChest_GR'\n",
    "json_file = r\"C:\\Users\\emman\\Desktop\\PROYECTOS_VS_CODE\\PRUEBAS_DE_PYTHON\\PadChest-GR\\grounded_reports_20240819.json\"\n",
    "\n",
    "# Uncomment and set your variables before running:\n",
    "ds, loader, stats, tok = build_padchest_loader(\n",
    "    dataframe=df_train,\n",
    "    root_dir=root_dir,\n",
    "    json_file=json_file,\n",
    "    batch_size=8,\n",
    "    num_workers=0,      # try 0 if on Windows/Colab and you hit issues\n",
    "    image_size=1024,\n",
    "    max_txt_len=64,   # None => auto from p95+8; or set e.g. 64\n",
    "    sentence_key=\"sentence_en\",\n",
    "    return_paths=False,\n",
    ")\n",
    "print(\"Auto stats (may be empty if max_txt_len was provided):\", stats)\n",
    "batch = next(iter(loader))\n",
    "print(batch[\"images\"].shape, batch[\"input_ids\"].shape, batch[\"attn_mask\"].shape)\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b87d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/10 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m slice_train_loader \u001b[38;5;241m=\u001b[39m islice(loader, \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      4\u001b[0m slice_valid_loader \u001b[38;5;241m=\u001b[39m islice(loader, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m train_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_clip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m val_stats \u001b[38;5;241m=\u001b[39m evaluate(model, slice_valid_loader, device, pad_id, num_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Train Loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, PPL=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mppl\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal Loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val PPL=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_ppl\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\emman\\Desktop\\PROYECTOS_VS_CODE\\PRUEBAS_DE_PYTHON\\Chest-X-ray-Diagnosis-Automated-Reporting-using-CNNs-and-LLMs---UDEM-PEF-Thesis-Fall-2025\\LSTMvsGPT\\GPT.py:470\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, loader, optimizer, device, pad_id, num_batches, grad_clip)\u001b[0m\n\u001b[0;32m    468\u001b[0m total_loss, total_pp, steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pixel_values, tgt_ids, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;129;01min\u001b[39;00m tqdm(loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39mnum_batches):\n\u001b[1;32m--> 470\u001b[0m     pixel_values \u001b[38;5;241m=\u001b[39m \u001b[43mpixel_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    471\u001b[0m     tgt_ids \u001b[38;5;241m=\u001b[39m tgt_ids\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;66;03m# Shift: inputs are tokens[:-1], labels are tokens[1:]\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# ---- Train a few slices just to validate wiring ----\n",
    "for epoch in range(50):\n",
    "    slice_train_loader = islice(loader, 10)\n",
    "    slice_valid_loader = islice(loader, 10)\n",
    "    train_stats = train_one_epoch(model, slice_train_loader, optimizer, device, pad_id, num_batches=10, grad_clip=1.0)\n",
    "    val_stats = evaluate(model, slice_valid_loader, device, pad_id, num_batches=10)\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss={train_stats['loss']:.4f}, PPL={train_stats['ppl']:.2f} | \"\n",
    "            f\"Val Loss={val_stats['val_loss']:.4f}, Val PPL={val_stats['val_ppl']:.2f}\")\n",
    "\n",
    "def sequence_ce_loss(logits, labels, pad_id):\n",
    "    \"\"\"\n",
    "    logits: (B, T, V) — corresponds to input_ids[:, :] positions\n",
    "    labels: (B, T) — next tokens; pad ignored\n",
    "    \"\"\"\n",
    "    B, T, V = logits.size()\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=pad_id, label_smoothing=0.1)\n",
    "    return loss_fn(logits.reshape(B * T, V), labels.reshape(B * T))\n",
    "\n",
    "@torch.no_grad()\n",
    "def batch_perplexity(logits, labels, pad_id):\n",
    "    loss = sequence_ce_loss(logits, labels, pad_id)\n",
    "    return float(math.exp(min(loss.item(), 20.0)))\n",
    "\n",
    "slice_test_loader = islice(loader, 1)\n",
    "test_stats = evaluate(model, slice_test_loader, device, pad_id, num_batches=1)\n",
    "print(f\"Test Loss={test_stats['val_loss']:.4f}, Test PPL={test_stats['val_ppl']:.2f}\")\n",
    "# ---- Quick generation sanity check ----\n",
    "with torch.no_grad():\n",
    "    for pixel_values, ids_loader, paths, raw_labels in test_loader:\n",
    "        pixel_values = pixel_values.to(device)\n",
    "        gen_ids = model.generate(\n",
    "            pixel_values=pixel_values,\n",
    "            bos_id=bos_id, eos_id=eos_id,\n",
    "            max_new_tokens=256, top_p=0.9, temperature=0.9, greedy=True\n",
    "        )\n",
    "        print(\"Predictions (first batch):\")\n",
    "        for i in range(min(gen_ids.size(0), 8)):\n",
    "            print(f\"\\nGEN {i+1}:\", tokenizer.decode(gen_ids[i].tolist()))\n",
    "            print(f\"TGT {i+1}:\", tokenizer.decode(ids_loader[i].tolist()))\n",
    "            # Calculate loss between generated and target sequences\n",
    "        del pixel_values, ids_loader, paths, raw_labels, gen_ids\n",
    "        torch.cuda.empty_cache()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890fd9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DINOv3PEF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
