{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5279cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Kept 47494/223462 rows with existing PNGs under C:\\Users\\emman\\Desktop\\PROYECTOS_VS_CODE\\PRUEBAS_DE_PYTHON\\CheXpertPlus\\PNG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/11874 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n",
      "Epoch 0:   8%|▊         | 999/11874 [08:41<1:34:35,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.5677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8%|▊         | 999/11874 [09:15<1:40:46,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.5846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Import CheXpertDataset and DINOEncoder ---\n",
    "from GPT import CheXpertDataset, dino_image_transform, build_valid_df, TEXT_COL, IMG_ROOT, CSV_PATH\n",
    "\n",
    "# --- GPT2 Decoder ---\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "class DINOv3Encoder(nn.Module):\n",
    "    def __init__(self, model_id=\"facebook/dinov3-vits16-pretrain-lvd1689m\", out_dim=384, tokens=8, freeze=True):\n",
    "        super().__init__()\n",
    "        from transformers import AutoModel\n",
    "        self.model = AutoModel.from_pretrained(model_id)\n",
    "        if freeze:\n",
    "            for p in self.model.parameters():\n",
    "                p.requires_grad = False\n",
    "        self.proj = nn.Linear(self.model.config.hidden_size, out_dim)\n",
    "        self.tokens = tokens\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, pixel_values):\n",
    "        out = self.model(pixel_values=pixel_values)\n",
    "        tokens = out.last_hidden_state  # [B, N, D]\n",
    "        # Use CLS + first N patch tokens\n",
    "        prefix = torch.cat([tokens[:, :1, :], tokens[:, 5:5+self.tokens, :]], dim=1)\n",
    "        prefix = self.proj(prefix)\n",
    "        return prefix  # [B, tokens+1, out_dim]\n",
    "\n",
    "class VisualPrefixGPT2(nn.Module):\n",
    "    def __init__(self, gpt2_name=\"gpt2\", vis_dim=384, num_prefix_tokens=8):\n",
    "        super().__init__()\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_name)\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(gpt2_name)\n",
    "        self.num_prefix_tokens = num_prefix_tokens\n",
    "        self.vis_to_prefix = nn.Linear(vis_dim, self.model.config.n_embd)\n",
    "\n",
    "    def encode_text(self, texts):\n",
    "        return self.tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    def forward(self, visual_tokens, input_ids, attention_mask=None, labels=None):\n",
    "        B, Tvis, Dv = visual_tokens.shape\n",
    "        prefix = self.vis_to_prefix(visual_tokens)\n",
    "        inputs_embeds = self.model.transformer.wte(input_ids)\n",
    "        full_embeds = torch.cat([prefix, inputs_embeds], dim=1)\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=input_ids.device)\n",
    "        vis_mask = torch.ones((B, Tvis), dtype=attention_mask.dtype, device=attention_mask.device)\n",
    "        full_mask = torch.cat([vis_mask, attention_mask], dim=1)\n",
    "        # Fix: pad labels with -100 for prefix tokens\n",
    "        if labels is not None:\n",
    "            pad_labels = torch.full((B, Tvis), -100, dtype=labels.dtype, device=labels.device)\n",
    "            full_labels = torch.cat([pad_labels, labels], dim=1)\n",
    "        else:\n",
    "            full_labels = None\n",
    "        return self.model(inputs_embeds=full_embeds, attention_mask=full_mask, labels=full_labels)\n",
    "\n",
    "# --- T5 Decoder ---\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "class DinoT5(nn.Module):\n",
    "    def __init__(self, t5_name=\"t5-base\", vis_dim=384):\n",
    "        super().__init__()\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(t5_name)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(t5_name)\n",
    "        self.vis_proj = nn.Linear(vis_dim, self.model.config.d_model)\n",
    "\n",
    "    def encode_visual(self, vtokens):\n",
    "        return self.vis_proj(vtokens)\n",
    "\n",
    "    def forward(self, vtokens, target_texts):\n",
    "        enc_vis = self.encode_visual(vtokens)\n",
    "        out = self.model(\n",
    "            encoder_outputs=(enc_vis, ),\n",
    "            labels=self.tokenizer(target_texts, return_tensors=\"pt\", padding=True, truncation=True).input_ids,\n",
    "            return_dict=True,\n",
    "        )\n",
    "        return out\n",
    "\n",
    "# --- Collate ---\n",
    "class CaptionCollate:\n",
    "    def __init__(self, tokenizer, pad_id):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_id = pad_id\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        images = torch.stack([b[\"image\"] for b in batch])\n",
    "        texts = [b[\"label\"] for b in batch]\n",
    "        return images, texts\n",
    "\n",
    "# --- Main ---\n",
    "option=\"A\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "valid_df = build_valid_df(CSV_PATH, IMG_ROOT)\n",
    "labels_as_str = valid_df[TEXT_COL].astype(str).tolist()\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\") if option == \"A\" else T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "pad_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else 0\n",
    "\n",
    "tf = dino_image_transform(img_size=1024)\n",
    "ds = CheXpertDataset(img_root=IMG_ROOT, csv=valid_df, transform=tf, text_col=TEXT_COL)\n",
    "collate_fn = CaptionCollate(tokenizer, pad_id)\n",
    "loader = DataLoader(ds, batch_size=4, shuffle=True, collate_fn=collate_fn, num_workers=0)\n",
    "\n",
    "if option == \"A\":\n",
    "    dino = DINOv3Encoder(out_dim=384, tokens=8).to(device)\n",
    "    dec = VisualPrefixGPT2(gpt2_name=\"gpt2\", vis_dim=384, num_prefix_tokens=9).to(device)\n",
    "else:\n",
    "    dino = DINOv3Encoder(out_dim=384, tokens=8).to(device)\n",
    "    dec = DinoT5(t5_name=\"t5-base\", vis_dim=384).to(device)\n",
    "\n",
    "optim = torch.optim.AdamW(dec.parameters(), lr=2e-5)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(2):\n",
    "    num_batches = 0\n",
    "    for images, texts in tqdm(loader, desc=f\"Epoch {epoch}\"):\n",
    "        num_batches += 1\n",
    "        images = images.to(device)\n",
    "        vis_tokens = dino(images)\n",
    "        if option == \"A\":\n",
    "            tok = dec.tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            input_ids = tok.input_ids.to(device)\n",
    "            labels = input_ids.clone()\n",
    "            out = dec(vis_tokens, input_ids=input_ids, labels=labels)\n",
    "            loss = out.loss\n",
    "        else:\n",
    "            out = dec(vis_tokens, texts)\n",
    "            loss = out.loss\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if num_batches == 1000:\n",
    "            break\n",
    "    print(f\"Epoch {epoch} loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88dddf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample loss (GPT2): 0.8682\n",
      "Length of generated ids: 110\n",
      "Length of target ids: 300\n",
      "Generated [0]: \n",
      " \n",
      "1.  Interval removal of the right chest tube.\n",
      " \n",
      "2.  Persistent small right pleural effusion.\n",
      " \n",
      " \n",
      "I have personally reviewed the images for this examination and agreed\n",
      "with the report transcribed above.\n",
      " \n",
      "\n",
      "Target   [0]:   \n",
      " \n",
      " SINGLE FRONTAL VIEW OF THE CHEST DEMONSTRATES STABLE APPEARANCE OF A \n",
      "HIATAL HERNIA, WHICH LIMITS EVALUATION OF THE LEFT LOWER LOBE.  \n",
      "RECOMMEND LATERAL VIEW FOR FURTHER EVALUATION.  THE REMAINING \n",
      "VISUALIZED LUNG FIELDS APPEAR CLEAR WITHOUT EVIDENCE OF PLEURAL \n",
      "EFFUSIONS OR PULMONARY EDEMA.  \n",
      " \n",
      " \n",
      "Length of generated ids: 110\n",
      "Length of target ids: 300\n",
      "Generated [1]: \n",
      " \n",
      "1.  Interval removal of the right chest tube.\n",
      " \n",
      "2.  Persistent small right pleural effusion.\n",
      " \n",
      " \n",
      "I have personally reviewed the images for this examination and agreed\n",
      "with the report transcribed above.\n",
      " \n",
      "\n",
      "Target   [1]: \n",
      " \n",
      "1.SINGLE FRONTAL VIEW OF THE CHEST DEMONSTRATES INTERVAL DEVELOPMENT \n",
      "OF PATCHY AREAS OF CONSOLIDATION THROUGHOUT THE BILATERAL LUNG FIELDS \n",
      "MOST CONFLUENT AT THE BILATERAL BASES.  FINDINGS MAY REPRESENT \n",
      "MULTIFOCAL PNEUMONIA INCLUDING ATYPICAL ORGANISMS.  A NEOPLASTIC \n",
      "ETIOLOGY IS LESS LIKELY GIVEN THE RAPID ONSET WHEN COMPARED TO PRIOR \n",
      "EXAM.  A LEFT-SIDED PLEURAL EFFUSION IS SEEN.\n",
      " \n",
      "2.THE CARDIOMEDIASTINAL SILHOUETTE IS WITHIN NORMAL LIMITS WITH AN \n",
      "ATHEROSCLEROTIC THORACIC AORTA. \n",
      " \n",
      "\n",
      "Length of generated ids: 110\n",
      "Length of target ids: 300\n",
      "Generated [2]: \n",
      "1. INTERVAL REMOVAL OF RIGHT INTERNAL JUGULAR CENTRAL VENOUS CATHETER.\n",
      "2. PERSISTENT LEFT PLEURAL EFFUSION AND LEFT BASILAR ATELECTASIS.\n",
      "3. PERSISTENT LEFT PLEURAL EFFUSION AND LEFT BASILAR ATELECTASIS.\n",
      "4. PERSISTENT LEFT PLEURAL EFFUSION AND LEFT BASE ATELECTASIS.\n",
      "\n",
      "Target   [2]: \n",
      "1. NO CHANGE IN LINES AND TUBES.\n",
      "2. EXAMINATION IS PERFORMED WITH PATIENT ROTATED TO THE RIGHT,\n",
      "ALLOWING FOR DIFFERENCES IN TECHNIQUE, THERE IS NO DEFINITE CHANGE\n",
      "WITH CARDIOMEGALY, MILD PULMONARY EDEMA AND LEFT RETROCARDIAC\n",
      "CONSOLIDATION.\n",
      "\n",
      "Length of generated ids: 110\n",
      "Length of target ids: 300\n",
      "Generated [3]: \n",
      " \n",
      "1.  Interval removal of the right chest tube.\n",
      " \n",
      "2.  Persistent mild pulmonary edema.\n",
      " \n",
      " \n",
      "I have personally reviewed the images for this examination and agreed\n",
      "with the report transcribed above.\n",
      " \n",
      "\n",
      "Target   [3]: \n",
      " \n",
      "1.FRONTAL AND LATERAL VIEWS OF THE CHEST DEMONSTRATE INTERVAL \n",
      "DEVELOPMENT OF A ROUNDED OPACITY PROJECTING OVER LEFT UPPER LUNG \n",
      "ZONE, WITH MILD TRACHEAL DEVIATION TO THE RIGHT.  THIS OPACITY MAY BE \n",
      "SECONDARY TO INFECTION, INCLUDING ATYPICAL ORGANISMS.  ALTERNATIVELY \n",
      "POSTOBSTRUCTIVE PNEUMONIA IS ALSO A DIAGNOSTIC CONSIDERATION.  THIS \n",
      "OPACITY LESS LIKELY REPRESENTS DRAMATIC INTERVAL GROWTH OF MALIGNANCY \n",
      "GIVEN THE LOCATION OF THE PATIENT'S PREVIOUSLY DESCRIBED RIGHT-SIDED \n",
      "LUNG NODULES.\n",
      " \n",
      "2.UNLESS CLINICAL DIAGNOSIS IS CLEAR, CT THORAX MAY BE USEFUL FOR \n",
      "FURTHER EVALUATION.\n",
      " \n",
      "3.PREVIOUSLY IDENTIFIED RIGHT-SIDED PULMONARY NODULES ARE NOT \n",
      "WELL-VISUALIZED ON THE CURRENT EXAM. \n",
      " \n",
      "4.DISCUSSED WITH ED fitmango 2230 HOURS \n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    image, target_text = next(iter(loader))\n",
    "    image = image.to(device)\n",
    "    vis_tokens = dino(image)\n",
    "    if option == \"A\":\n",
    "        tok = dec.tokenizer(target_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        input_ids = tok.input_ids.to(device)\n",
    "        labels = input_ids.clone()\n",
    "        out = dec(vis_tokens, input_ids=input_ids, labels=labels)\n",
    "        loss = out.loss\n",
    "        print(f\"Sample loss (GPT2): {loss.item():.4f}\")\n",
    "\n",
    "        # Generate text from visual prefix\n",
    "        prefix_embeds = dec.vis_to_prefix(vis_tokens)\n",
    "        text_embeds = dec.model.transformer.wte(input_ids)\n",
    "        full_embeds = torch.cat([prefix_embeds, text_embeds], dim=1)\n",
    "        # Attention mask for prefix + text\n",
    "        full_mask = torch.ones(full_embeds.shape[:2], dtype=torch.long, device=full_embeds.device)\n",
    "        gen_ids = dec.model.generate(\n",
    "            inputs_embeds=prefix_embeds,\n",
    "            attention_mask=torch.ones(prefix_embeds.shape[:2], dtype=torch.long, device=prefix_embeds.device),\n",
    "            max_new_tokens=124,\n",
    "            pad_token_id=dec.tokenizer.eos_token_id,\n",
    "            do_sample=False,\n",
    "        )\n",
    "        # Decode and print for each sample in batch\n",
    "        for i in range(gen_ids.shape[0]):\n",
    "            generated_text = dec.tokenizer.decode(gen_ids[i], skip_special_tokens=True)\n",
    "            target_text_decoded = dec.tokenizer.decode(input_ids[i], skip_special_tokens=True)\n",
    "            print(f\"Length of generated ids: {len(gen_ids[i])}\")\n",
    "            print(f\"Length of target ids: {len(input_ids[i])}\")\n",
    "            print(f\"Generated [{i}]:\", generated_text)\n",
    "            print(f\"Target   [{i}]:\", target_text_decoded)\n",
    "    else:\n",
    "        out = dec(vis_tokens, target_text)\n",
    "        loss = out.loss\n",
    "        print(f\"Sample loss (T5): {loss.item():.4f}\")\n",
    "        gen_ids = dec.model.generate(inputs_embeds=dec.encode_visual(vis_tokens), max_new_tokens=64)\n",
    "        for i in range(gen_ids.shape[0]):\n",
    "            generated_text = dec.tokenizer.decode(gen_ids[i], skip_special_tokens=True)\n",
    "            print(f\"Generated [{i}]:\", generated_text)\n",
    "            print(f\"Target   [{i}]:\", target_text[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa755253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DINOv3PEF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
