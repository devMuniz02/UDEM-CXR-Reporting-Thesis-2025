{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd0b5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local images_dir detected; filtering rows with missing PNGs...\n",
      "[INFO] Kept 82440/188960 rows with existing PNGs\n",
      "DataLoader created with dataset length: 320412\n",
      "MIMIC dataset size:  237972\n",
      "CheXpert dataset size:  82440\n",
      "Batch image tensor shape: torch.Size([32, 3, 512, 512])\n",
      "Batch findings shape: 32\n",
      "Batch image paths shape: 32\n"
     ]
    }
   ],
   "source": [
    "# ---------- Example DataLoading Datasets MIMIC/CHEXPERT ----------\n",
    "import torch\n",
    "from torch.utils.data import ConcatDataset, DataLoader, WeightedRandomSampler\n",
    "from utils.data.chexpert_dataset import CHEXPERTDataset\n",
    "from utils.data.mimic_dataset import MIMICDataset\n",
    "from utils.processing import image_transform, loader\n",
    "\n",
    "# MODELS\n",
    "MODELS_DIR = \"models/\"\n",
    "SEGMENTER_MODEL_PATH = f\"{MODELS_DIR}dino_unet_decoder_finetuned.pth\"\n",
    "save_path = f\"{MODELS_DIR}complete_model.pth\"\n",
    "checkpoint_path = f\"{MODELS_DIR}model_checkpoint.pth\"\n",
    "\n",
    "# CheXpert\n",
    "CHEXPERT_DIR = \"Datasets/CheXpertPlus\"\n",
    "chexpert_paths = {\n",
    "    \"chexpert_data_path\": f\"{CHEXPERT_DIR}/PNG\",  # base PNG folder\n",
    "    \"chexpert_data_csv\": f\"{CHEXPERT_DIR}/df_chexpert_plus_240401.csv\",\n",
    "}\n",
    "\n",
    "# MIMIC\n",
    "MIMIC_DIR = \"Datasets/MIMIC\"\n",
    "mimic_paths = {\n",
    "    \"mimic_data_path\": MIMIC_DIR,\n",
    "    \"mimic_splits_csv\": f\"{MIMIC_DIR}/mimic-cxr-2.0.0-split.csv.gz\",\n",
    "    \"mimic_metadata_csv\": f\"{MIMIC_DIR}/mimic-cxr-2.0.0-metadata.csv\",\n",
    "    \"mimic_reports_path\": f\"{MIMIC_DIR}/cxr-record-list.csv.gz\",  # must contain 'path'\n",
    "}\n",
    "\n",
    "# Build dataframes\n",
    "MIMIC_df, CHEXPERT_df = loader(chexpert_paths, mimic_paths, split=\"train\")\n",
    "\n",
    "# Example dataset usage\n",
    "mimic_images_dir = \"Datasets/MIMIC/matched_images_and_masks_mimic_224/images\"\n",
    "mimic_reports_dir = \"Datasets/MIMIC\"  # base; dataset derives \"<rel_dir>.txt\"\n",
    "\n",
    "\n",
    "transform = image_transform(img_size=512)\n",
    "mimic_ds = MIMICDataset(MIMIC_df, mimic_images_dir, mimic_reports_dir, transform=transform)\n",
    "\n",
    "chexpert_ds = CHEXPERTDataset(\n",
    "    CHEXPERT_df,\n",
    "    chexpert_paths[\"chexpert_data_path\"],\n",
    "    split=\"train\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "mixed = ConcatDataset([mimic_ds, chexpert_ds])\n",
    "n1, n2 = len(mimic_ds), len(chexpert_ds)\n",
    "p1, p2 = 0.7, 0.3  # desired sampling ratio\n",
    "\n",
    "# per-sample weights: higher weight â†’ sampled more often\n",
    "w1 = torch.full((n1,), fill_value=p1 / max(n1, 1), dtype=torch.float)\n",
    "w2 = torch.full((n2,), fill_value=p2 / max(n2, 1), dtype=torch.float)\n",
    "weights = torch.cat([w1, w2])\n",
    "\n",
    "sampler = WeightedRandomSampler(weights, num_samples=n1 + n2, replacement=True)\n",
    "\n",
    "# Dataloader tuning for cloud I/O\n",
    "loader = DataLoader(\n",
    "    mixed,\n",
    "    batch_size=32,\n",
    "    sampler=sampler,\n",
    "    # num_workers=os.cpu_count() // 2 if os.cpu_count() else 4,  # adjust on your VM\n",
    "    # persistent_workers=True,           # reuses workers between iterations\n",
    "    # prefetch_factor=4,                 # each worker prefetches batches\n",
    "    # pin_memory=True,                   # if using CUDA\n",
    "    # drop_last=False\n",
    ")\n",
    "print(\"DataLoader created with dataset length:\", len(mixed))\n",
    "print(\"MIMIC dataset size: \", len(mimic_ds))\n",
    "print(\"CheXpert dataset size: \", len(chexpert_ds))\n",
    "# Example read\n",
    "images, findings, image_paths, _ = next(iter(loader))\n",
    "print(\"Batch image tensor shape:\", getattr(images, \"shape\", \"N/A\"))\n",
    "print(\"Batch findings shape:\", getattr(findings, \"shape\", len(findings)))\n",
    "print(\"Batch image paths shape:\", getattr(image_paths, \"shape\", len(image_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d90fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-chest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
